{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env에서 API 키 로드\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# PDF 로드\n",
    "loader = PyPDFLoader(\"data/5._Linear_Regression.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 텍스트를 작은 조각으로 분할 (RAG에 적합하도록)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fn/7bjmjvmn2d30b47j1yfz_5jm0000gn/T/ipykernel_57810/4074028122.py:5: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# OpenAI 임베딩 설정\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "# 벡터 저장소 생성\n",
    "vectorstore = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fn/7bjmjvmn2d30b47j1yfz_5jm0000gn/T/ipykernel_57810/3691347973.py:8: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=openai_api_key)\n",
      "/var/folders/fn/7bjmjvmn2d30b47j1yfz_5jm0000gn/T/ipykernel_57810/3691347973.py:66: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(input[\"query\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레포트:\n",
      "# 강의 자료 레포트\n",
      "\n",
      "## 1. 강의 내용 요약\n",
      "\n",
      "### 1. 선형 회귀 모델(Linear Regression)\n",
      "선형 회귀 모델은 독립 변수(X)와 종속 변수(Y) 간의 관계를 선형적으로 모델링하는 통계적 기법으로, 데이터 점들을 기반으로 최적의 직선을 찾아 예측을 수행한다. 이 모델은 회귀 계수(β)를 통해 각 독립 변수의 중요도를 평가할 수 있으며, 예측된 Y값은 주어진 X값에 의해 설명될 수 있다. 선형 회귀는 예측 및 추세 분석에 널리 사용되며, 간단하고 해석하기 쉬운 특성으로 인해 많이 활용된다.\n",
      "\n",
      "### 2. 데이터 분할(Training and Test Sets)\n",
      "모델의 일반화 능력을 평가하기 위해 데이터는 훈련 데이터와 테스트 데이터로 분할된다. 훈련 데이터는 모델을 학습하는 데 사용되며, 테스트 데이터는 학습된 모델의 성능을 검증하는 데 활용된다. 이 과정은 과적합(overfitting)을 방지하고 모델의 예측력을 평가하는 데 필수적이다. 일반적으로 데이터의 70-80%는 훈련에, 나머지 20-30%는 테스트에 할당되는 것이 일반적이다.\n",
      "\n",
      "### 3. 모델 구축 및 테스트\n",
      "훈련 데이터를 사용하여 모델을 구축한 후, 이를 통해 예측값을 생성한다. 예를 들어, 훈련 데이터에서 얻은 입력(X_tr)을 기반으로 종속 변수(Y_tr)를 예측하는 모델(f)을 구성하고, 이후 테스트 데이터(X_te)를 이용해 모델의 예측 성능을 평가한다. 이 과정을 통해 모델이 실제 데이터에 대한 반응을 얼마나 잘 검증하는지를 확인할 수 있다.\n",
      "\n",
      "이 자료는 선형 회귀 모델의 기본 개념과 데이터 분할 방법론, 그리고 모델 구축 및 테스트 과정을 상세히 설명하고 있으며, 머신 러닝의 기초를 이해하는 데 중요한 요소들을 포함하고 있다. 각 단계에서의 데이터 활용과 모델 평가 방법은 머신 러닝 프로젝트의 성공을 좌우하는 핵심 요소임을 강조하고 있다.\n",
      "\n",
      "## 2. 강의 내용 퀴즈\n",
      "\n",
      "### 객관식 퀴즈\n",
      "\n",
      "Q1. 선형 회귀 모델에서 훈련 데이터와 테스트 데이터를 분리하는 주된 목적은 무엇인가요?  \n",
      "a) 모델의 복잡성을 줄이기 위해  \n",
      "b) 모델의 일반화 능력을 평가하기 위해  \n",
      "c) 데이터의 양을 늘리기 위해  \n",
      "d) 피처의 중요도를 분석하기 위해  \n",
      "정답: b\n",
      "\n",
      "Q2. 선형 회귀 모델의 예측 함수 \\( f(X) \\)가 훈련 데이터 \\( Y_{tr} \\)에 대해 근사하는 방식은 무엇인가요?  \n",
      "a) \\( Y_{tr} \\approx f(X_{tr}) \\)로 표현된다  \n",
      "b) \\( Y_{tr} = f(X_{tr}) + \\epsilon \\)로 표현된다  \n",
      "c) \\( Y_{tr} \\approx X_{tr} \\cdot \\beta \\)로 표현된다  \n",
      "d) \\( Y_{tr} = f(X_{tr}) - \\epsilon \\)로 표현된다  \n",
      "정답: b\n",
      "\n",
      "Q3. 선형 회귀 모델에서 테스트 데이터 \\( Y_{te} \\)의 예측을 어떻게 표현할 수 있나요?  \n",
      "a) \\( Y_{te} \\approx f(X_{tr}) \\)  \n",
      "b) \\( Y_{te} \\approx f(X_{te}) \\)  \n",
      "c) \\( Y_{te} = f(X_{te}) + \\epsilon \\)  \n",
      "d) \\( Y_{te} = f(X_{te}) - \\epsilon \\)  \n",
      "정답: b\n",
      "\n",
      "Q4. 선형 회귀에서 훈련 데이터와 테스트 데이터의 비율 설정이 모델 성능에 미치는 영향은 무엇인가요?  \n",
      "a) 데이터의 크기와 무관하게 항상 동일한 효과를 가진다  \n",
      "b) 모델의 과적합과 과소적합을 조절하는 데 중요한 역할을 한다  \n",
      "c) 성능에 영향을 미치지 않는다  \n",
      "d) 훈련 데이터의 양이 많을수록 항상 좋은 성능을 보인다  \n",
      "정답: b\n",
      "\n",
      "Q5. 선형 회귀 모델에서 주어진 데이터의 분포가 비선형일 경우, 어떤 접근 방법이 유효할까요?  \n",
      "a) 데이터를 더 많이 수집한다  \n",
      "b) 선형 회귀 모델을 그대로 사용한다  \n",
      "c) 비선형 변환을 적용하거나 다른 모델을 고려한다  \n",
      "d) 테스트 데이터의 양을 줄인다  \n",
      "정답: c\n",
      "\n",
      "### 주관식 퀴즈\n",
      "\n",
      "Q1. 선형 회귀 모델에서 모델의 일반화 능력을 높이기 위해 데이터 분할 시 고려해야 할 사항들을 설명하시오.  \n",
      "답변: 모델의 일반화 능력을 높이기 위해 데이터 분할 시 고려해야 할 사항은 우선 데이터의 양과 대표성을 고려하는 것이 중요하다. 훈련 데이터는 다양한 상황을 반영해야 하며, 테스트 데이터는 훈련 데이터와 중복되지 않아야 한다. 또한, 데이터의 비율 설정은 모델의 과적합 및 과소적합을 방지하는 데 중요한 역할을 하므로 신중하게 결정해야 한다. 마지막으로, 교차 검증을 통해 여러 번의 훈련과 검증을 반복함으로써 모델의 일반화 능력을 더욱 향상시킬 수 있다.\n",
      "\n",
      "Q2. 훈련 데이터와 테스트 데이터의 선택이 모델의 성능 평가에 미치는 영향을 분석하시오.  \n",
      "답변: 훈련 데이터와 테스트 데이터의 선택은 모델 성능 평가에 결정적인 영향을 미친다. 훈련 데이터가 충분하지 않거나 편향된 경우 모델이 실제 데이터를 잘 반영하지 못하여 과적합 또는 과소적합의 위험이 증가한다. 반면, 테스트 데이터가 훈련 데이터와 너무 유사하면 모델의 일반화 능력을 잘 평가할 수 없다. 따라서 훈련 데이터는 다양한 샘플을 포함해야 하며, 테스트 데이터는 독립적으로 선정하여 모델이 실제 환경에서 어떻게 작동하는지를 정확하게 평가할 수 있도록 해야 한다. 이러한 과정은 모델의 신뢰성을 높이고, 실제 응용에 있어서의 성능을 보장하는 데 필수적이다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=openai_api_key)\n",
    "\n",
    "# 벡터 저장소 (이미 생성된 texts 사용)\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "vectorstore = Chroma.from_documents(texts, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# 1. 요약 프롬프트\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=\"\"\"\n",
    "    다음 강의 자료를 기반으로 주요 내용을 상세하게 요약해줘. \n",
    "    - \"이것은 abc에 대한 내용입니다\" 같은 추상적 설명은 피하고, 자료의 실제 내용을 기반으로 구체적으로 작성해줘.\n",
    "    - 각 주요 항목(예: 섹션, 주제)을 구분하고, 항목별로 상세한 설명(최소 2~3문장)을 포함해줘.\n",
    "    - 전체 요약은 500~700자 정도로, 한 장 분량으로 정리해줘.\n",
    "    자료: {context}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 2. 퀴즈 프롬프트\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=\"\"\"\n",
    "    다음 강의 자료를 기반으로 고급 수준의 객관식 퀴즈 5개와 주관식 퀴즈 2개를 만들어줘. \n",
    "    퀴즈는 단순 암기나 정의 확인이 아니라, 자료의 개념을 깊이 이해하고 응용력을 요구해야 해.\n",
    "    - 객관식: 각 질문은 4개의 선택지를 포함하며, 선택지는 혼동을 주지 않고 사고를 자극해야 함. 형식:\n",
    "      Q1. 질문\n",
    "      a) 선택지1  b) 선택지2  c) 선택지3  d) 선택지4\n",
    "      정답: a\n",
    "    - 주관식: 분석, 비교, 또는 문제 해결을 요구하며, 정답은 간결한 문장으로.\n",
    "    자료: {context}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 3. 레포트 프롬프트\n",
    "prompt3 = PromptTemplate(\n",
    "    input_variables=[\"summary\", \"quizzes\"],\n",
    "    template=\"\"\"\n",
    "    다음 정보를 기반으로 강의 자료 레포트를 작성해줘. \n",
    "    레포트는 아래 구조를 따라야 해:\n",
    "    ---\n",
    "    # 강의 자료 레포트\n",
    "    ## 1. 강의 내용 요약\n",
    "    {summary}\n",
    "\n",
    "    ## 2. 강의 내용 퀴즈\n",
    "    {quizzes}\n",
    "    ---\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 체인 정의\n",
    "chain1 = prompt1 | llm | StrOutputParser()  # 요약 생성\n",
    "chain2 = prompt2 | llm | StrOutputParser()  # 퀴즈 생성\n",
    "chain3 = prompt3 | llm | StrOutputParser()  # 레포트 작성\n",
    "\n",
    "# RAG 검색을 위한 컨텍스트 생성 함수\n",
    "def get_context(input):\n",
    "    docs = retriever.get_relevant_documents(input[\"query\"])\n",
    "    return {\"context\": \"\\n\".join([doc.page_content for doc in docs])}\n",
    "\n",
    "# 병렬 실행 설정\n",
    "parallel_chain = RunnableParallel(\n",
    "    {\n",
    "        \"summary\": RunnablePassthrough.assign(**{\"context\": get_context}) | chain1,\n",
    "        \"quizzes\": RunnablePassthrough.assign(**{\"context\": get_context}) | chain2\n",
    "    }\n",
    ")\n",
    "\n",
    "# 전체 파이프라인 구성\n",
    "overall_chain = (\n",
    "    {\"query\": RunnablePassthrough()}  # 입력 query 전달\n",
    "    | parallel_chain                  # 요약과 퀴즈 병렬 실행\n",
    "    | chain3                          # 레포트 생성\n",
    ")\n",
    "\n",
    "# 실행\n",
    "result = overall_chain.invoke(\"강의 자료 정리와 퀴즈 생성을 위한 레포트를 작성해줘\")\n",
    "print(f\"레포트:\\n{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown 파일로 저장 완료: lecture_report.md\n"
     ]
    }
   ],
   "source": [
    "# Markdown 파일로 저장\n",
    "with open(\"lecture_report.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(result)\n",
    "\n",
    "print(\"Markdown 파일로 저장 완료: lecture_report.md\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
