{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBSFmmW0B_O2"
   },
   "source": [
    "# [실습] LangChain Tool과 Agent\n",
    "\n",
    "\n",
    "Agent는 사용자의 요청에 대해, 툴(Tool)로 표현되는 외부 모듈을 활용하여 문제를 해결하는 기능입니다.     \n",
    "\n",
    "Tool은 LLM이 답변을 출력하기 위해 활용할 수 있는 다양한 수단을 의미합니다.   \n",
    "LLM은 Tool을 사용하기 위해 Tool 이름과 Argument를 생성하는데요.\n",
    "\n",
    "이 Tool 실행을 자동화하여 LLM을 반복적으로 실행하여 최종 단계에 도달하는 방법이 Agent입니다.\n",
    "\n",
    "<br><br><br>\n",
    "Agent의 작동 방식은 아래와 같습니다.\n",
    "\n",
    "1. 에이전트에 입력이 주어지면, 툴을 사용하는 액션(Action)을 결정합니다.\n",
    "1. 툴의 사용 결과가 에이전트에 전달되면, 이를 활용하여 다음 액션을 정합니다.\n",
    "1. 이후, 원하는 결과에 도달할 때까지 반복됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHjWGmc3i5fU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/homebrew/anaconda3/lib/python3.11/site-packages (0.3.19)\n",
      "Requirement already satisfied: langchain-openai in /opt/homebrew/anaconda3/lib/python3.11/site-packages (0.3.7)\n",
      "Requirement already satisfied: langchain-community in /opt/homebrew/anaconda3/lib/python3.11/site-packages (0.3.18)\n",
      "Requirement already satisfied: langgraph in /opt/homebrew/anaconda3/lib/python3.11/site-packages (0.2.52)\n",
      "Requirement already satisfied: pypdf in /opt/homebrew/anaconda3/lib/python3.11/site-packages (4.3.1)\n",
      "Requirement already satisfied: chromadb in /opt/homebrew/anaconda3/lib/python3.11/site-packages (0.5.3)\n",
      "Requirement already satisfied: wikipedia in /opt/homebrew/anaconda3/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: tavily-python in /opt/homebrew/anaconda3/lib/python3.11/site-packages (0.5.0)\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/anaconda3/lib/python3.11/site-packages (3.7.2)\n",
      "Requirement already satisfied: langchain-experimental in /opt/homebrew/anaconda3/lib/python3.11/site-packages (0.0.58)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.40)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langchain) (0.1.125)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langchain) (2.10.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.4 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langchain-openai) (1.65.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langchain-community) (2.4.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langgraph) (2.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.32 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langgraph) (0.1.36)\n",
      "Requirement already satisfied: build>=1.0.3 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (1.2.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (0.115.5)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (0.30.6)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (3.6.6)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (0.19.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (4.66.5)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (1.64.3)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (4.0.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (30.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (3.10.11)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from chromadb) (0.27.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from matplotlib) (10.4.0)\n",
      "Collecting pyparsing<3.1,>=2.3.1 (from matplotlib)\n",
      "  Obtaining dependency information for pyparsing<3.1,>=2.3.1 from https://files.pythonhosted.org/packages/6c/10/a7d0fa5baea8fe7b50f448ab742f26f52b80bfca85ac2be9d35cdd9a3246/pyparsing-3.0.9-py3-none-any.whl.metadata\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "INFO: pip is looking at multiple versions of langchain-experimental to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-experimental\n",
      "  Obtaining dependency information for langchain-experimental from https://files.pythonhosted.org/packages/b2/27/fe8caa4884611286b1f7d6c5cfd76e1fef188faaa946db4fde6daa1cd2cd/langchain_experimental-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: pyproject_hooks in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb) (0.41.3)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (4.6.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.35.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.5)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.4.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.65.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.25.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.46b0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.46b0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.46b0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (75.1.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.12.25)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb) (0.26.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (13.8.1)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.20.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from beautifulsoup4->wikipedia) (2.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.11.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Downloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyparsing, langchain-experimental\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.2.1\n",
      "    Uninstalling pyparsing-3.2.1:\n",
      "      Successfully uninstalled pyparsing-3.2.1\n",
      "  Attempting uninstall: langchain-experimental\n",
      "    Found existing installation: langchain-experimental 0.0.58\n",
      "    Uninstalling langchain-experimental-0.0.58:\n",
      "      Successfully uninstalled langchain-experimental-0.0.58\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langflow-base 0.0.96 requires aiofiles<25.0.0,>=24.1.0, but you have aiofiles 23.2.1 which is incompatible.\n",
      "langflow-base 0.0.96 requires crewai<0.37.0,>=0.36.0, but you have crewai 0.28.8 which is incompatible.\n",
      "langflow-base 0.0.96 requires docstring-parser<0.17,>=0.16, but you have docstring-parser 0.15 which is incompatible.\n",
      "langflow-base 0.0.96 requires fastapi<0.112.0,>=0.111.0, but you have fastapi 0.115.5 which is incompatible.\n",
      "langflow-base 0.0.96 requires langchain<0.3.0,>=0.2.0, but you have langchain 0.3.19 which is incompatible.\n",
      "langflow-base 0.0.96 requires langchain-core<0.3.0,>=0.2.32, but you have langchain-core 0.3.40 which is incompatible.\n",
      "langflow-base 0.0.96 requires langchain-experimental<0.0.62,>=0.0.61, but you have langchain-experimental 0.3.4 which is incompatible.\n",
      "langflow-base 0.0.96 requires orjson==3.10.0, but you have orjson 3.10.11 which is incompatible.\n",
      "langflow-base 0.0.96 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
      "langflow-base 0.0.96 requires python-multipart<0.0.8,>=0.0.7, but you have python-multipart 0.0.12 which is incompatible.\n",
      "langflow-base 0.0.96 requires typer<0.13.0,>=0.12.0, but you have typer 0.15.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-experimental-0.3.4 pyparsing-3.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-openai langchain-community langgraph pypdf chromadb wikipedia tavily-python wikipedia matplotlib langchain-experimental\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6W3hW1HngUw"
   },
   "source": [
    "## OpenAI API로 Agent 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "isPOel4VngUx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "env_path = Path(\"/Users/blueno/UNO/SKALA/SKALA/.env\")\n",
    "load_dotenv(dotenv_path=env_path, override=True)\n",
    "\n",
    "# 환경 변수 확인\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRfV-aKKngUx"
   },
   "source": [
    "Agent는 포맷에 맞는 입/출력의 반복을 통해 문제를 해결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "630LrjNvngUx"
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    # __init__ : Agent 클래스가 생성될 때 호출되는 함수\n",
    "    def __init__(self, system_prompt=\"\"):\n",
    "        self.system_prompt = system_prompt\n",
    "        self.messages = []\n",
    "        # message를 저장\n",
    "\n",
    "        self.messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "    # __call__ : Agent 클래스가 호출될 때 호출되는 함수\n",
    "    # message와 result를 생성하고 이를 messages에 추가\n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    # execute : 현재까지의 message로 답변 생성\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "                        model=\"gpt-4o-mini\",\n",
    "                        temperature=0,\n",
    "                        messages=self.messages)\n",
    "        return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VGvt-8UingUx"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "당신은 질문에 답변하기 위해 Thought, Action, PAUSE, Observation의 루프를 사용하는 인공지능 비서입니다.\n",
    "루프의 끝에는 답변을 출력합니다.\n",
    "질문에 대한 답변을 설명하기 위해 Thought를 사용합니다.\n",
    "Action을 사용하여 사용 가능한 작업 중 하나를 실행하고 PAUSE를 반환합니다.\n",
    "Observation은 해당 작업을 실행한 결과입니다.\n",
    "\n",
    "사용 가능한 작업은 다음과 같습니다:\n",
    "\n",
    "\n",
    "search_number:\n",
    "예시) search_number: 전우치\n",
    "연락처 목록에서 이름을 검색하고 해당 이름의 전화번호를 반환합니다.\n",
    "\n",
    "send_message:\n",
    "예시) send_message: 010-1234-5678\n",
    "전화번호를 사용하여 메시지를 보내고 메시지를 성공적으로 보냈다는 메시지를 반환합니다.\n",
    "\n",
    "다음은 예시 사용 사례입니다:\n",
    "\n",
    "Question: 홍길동의 전화번호는 무엇입니까?\n",
    "Thought: 홍길동의 전화번호를 찾기 위해 search_number 작업을 사용해야 한다.\n",
    "Action: search_number: 홍길동\n",
    "PAUSE\n",
    "\n",
    "그 이후 작업의 결과와 함께 다시 호출됩니다.\n",
    "Observation은 외부에서 입력되는 메시지입니다. 임의로 생성할 수 없습니다.:\n",
    "\n",
    "Observation: 010-4539-2918\n",
    "\n",
    "이제 답변을 출력합니다:\n",
    "\n",
    "Answer: 홍길동의 전화번호는 010-4539-2918입니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8rWq6xzEngUx"
   },
   "outputs": [],
   "source": [
    "def send_message(recipient):\n",
    "    return recipient+ \"에 메시지를 성공적으로 보냈습니다.\"\n",
    "\n",
    "def search_number(name):\n",
    "    if name == '홍길동':\n",
    "        return(\"010-4539-2918\")\n",
    "    elif name == '전우치':\n",
    "        return (\"010-1234-5678\")\n",
    "    elif name == '이순신':\n",
    "        return(\"010-9876-5432\")\n",
    "known_actions = {\n",
    "    \"send_message\": send_message,\n",
    "    \"search_number\": search_number\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fOgCUxMBngUy"
   },
   "outputs": [],
   "source": [
    "abot = Agent(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GUQ7T8QmngUy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 홍길동의 전화번호를 찾기 위해 search_number 작업을 사용해야 한다.  \n",
      "Action: search_number: 홍길동  \n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "result = abot(\"홍길동의 전화번호는 무엇입니까?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JAzZEy82ngUy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'010-4539-2918'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = search_number(\"홍길동\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TRH72eP0ngUy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Observation: 010-4539-2918'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(result)\n",
    "next_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "QHw5rL9dngUy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: 홍길동의 전화번호는 010-4539-2918입니다.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RNEu6fQNngUy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\n당신은 질문에 답변하기 위해 Thought, Action, PAUSE, Observation의 루프를 사용하는 인공지능 비서입니다.\\n루프의 끝에는 답변을 출력합니다.\\n질문에 대한 답변을 설명하기 위해 Thought를 사용합니다.\\nAction을 사용하여 사용 가능한 작업 중 하나를 실행하고 PAUSE를 반환합니다.\\nObservation은 해당 작업을 실행한 결과입니다.\\n\\n사용 가능한 작업은 다음과 같습니다:\\n\\n\\nsearch_number:\\n예시) search_number: 전우치\\n연락처 목록에서 이름을 검색하고 해당 이름의 전화번호를 반환합니다.\\n\\nsend_message:\\n예시) send_message: 010-1234-5678\\n전화번호를 사용하여 메시지를 보내고 메시지를 성공적으로 보냈다는 메시지를 반환합니다.\\n\\n다음은 예시 사용 사례입니다:\\n\\nQuestion: 홍길동의 전화번호는 무엇입니까?\\nThought: 홍길동의 전화번호를 찾기 위해 search_number 작업을 사용해야 한다.\\nAction: search_number: 홍길동\\nPAUSE\\n\\n그 이후 작업의 결과와 함께 다시 호출됩니다.\\nObservation은 외부에서 입력되는 메시지입니다. 임의로 생성할 수 없습니다.:\\n\\nObservation: 010-4539-2918\\n\\n이제 답변을 출력합니다:\\n\\nAnswer: 홍길동의 전화번호는 010-4539-2918입니다.\\n'},\n",
       " {'role': 'user', 'content': '홍길동의 전화번호는 무엇입니까?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Thought: 홍길동의 전화번호를 찾기 위해 search_number 작업을 사용해야 한다.  \\nAction: search_number: 홍길동  \\nPAUSE'},\n",
       " {'role': 'user', 'content': 'Observation: 010-4539-2918'},\n",
       " {'role': 'assistant', 'content': 'Answer: 홍길동의 전화번호는 010-4539-2918입니다.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Y30n-LGQngUz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 전우치에게 메시지를 보내기 위해 먼저 그의 전화번호를 찾아야 한다. 따라서 search_number 작업을 사용해야 한다.  \n",
      "Action: search_number: 전우치  \n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "abot = Agent(prompt)\n",
    "question = \"\"\"전우치에게 메시지 보내 주세요.\"\"\"\n",
    "print(abot(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oWjWILgpngUz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: 010-1234-5678\n"
     ]
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(search_number(\"전우치\"))\n",
    "print(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SOGsisFzngUz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 전우치의 전화번호를 찾았으므로, 이제 이 번호로 메시지를 보내야 한다. send_message 작업을 사용해야 한다.  \n",
      "Action: send_message: 010-1234-5678  \n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "print(abot(next_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5AHnTzqCngUz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: 010-1234-5678에 메시지를 성공적으로 보냈습니다.\n"
     ]
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(send_message(\"010-1234-5678\"))\n",
    "print(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Tu-Ov6_wngUz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: 전우치에게 메시지를 성공적으로 보냈습니다.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "rEuRxo98ngUz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\n당신은 질문에 답변하기 위해 Thought, Action, PAUSE, Observation의 루프를 사용하는 인공지능 비서입니다.\\n루프의 끝에는 답변을 출력합니다.\\n질문에 대한 답변을 설명하기 위해 Thought를 사용합니다.\\nAction을 사용하여 사용 가능한 작업 중 하나를 실행하고 PAUSE를 반환합니다.\\nObservation은 해당 작업을 실행한 결과입니다.\\n\\n사용 가능한 작업은 다음과 같습니다:\\n\\n\\nsearch_number:\\n예시) search_number: 전우치\\n연락처 목록에서 이름을 검색하고 해당 이름의 전화번호를 반환합니다.\\n\\nsend_message:\\n예시) send_message: 010-1234-5678\\n전화번호를 사용하여 메시지를 보내고 메시지를 성공적으로 보냈다는 메시지를 반환합니다.\\n\\n다음은 예시 사용 사례입니다:\\n\\nQuestion: 홍길동의 전화번호는 무엇입니까?\\nThought: 홍길동의 전화번호를 찾기 위해 search_number 작업을 사용해야 한다.\\nAction: search_number: 홍길동\\nPAUSE\\n\\n그 이후 작업의 결과와 함께 다시 호출됩니다.\\nObservation은 외부에서 입력되는 메시지입니다. 임의로 생성할 수 없습니다.:\\n\\nObservation: 010-4539-2918\\n\\n이제 답변을 출력합니다:\\n\\nAnswer: 홍길동의 전화번호는 010-4539-2918입니다.\\n'},\n",
       " {'role': 'user', 'content': '전우치에게 메시지 보내 주세요.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Thought: 전우치에게 메시지를 보내기 위해 먼저 그의 전화번호를 찾아야 한다. 따라서 search_number 작업을 사용해야 한다.  \\nAction: search_number: 전우치  \\nPAUSE'},\n",
       " {'role': 'user', 'content': 'Observation: 010-1234-5678'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Thought: 전우치의 전화번호를 찾았으므로, 이제 이 번호로 메시지를 보내야 한다. send_message 작업을 사용해야 한다.  \\nAction: send_message: 010-1234-5678  \\nPAUSE'},\n",
       " {'role': 'user', 'content': 'Observation: 010-1234-5678에 메시지를 성공적으로 보냈습니다.'},\n",
       " {'role': 'assistant', 'content': 'Answer: 전우치에게 메시지를 성공적으로 보냈습니다.'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Zv3XohCSngUz"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "action_re = re.compile('^Action: (\\w+): (.*)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "K0EM9MMcngUz"
   },
   "outputs": [],
   "source": [
    "def query(question, max_turns=5):\n",
    "    i = 0\n",
    "    bot = Agent(prompt)\n",
    "    next_prompt = question\n",
    "    while i < max_turns:\n",
    "        i += 1\n",
    "        result = bot(next_prompt)\n",
    "        print(result)\n",
    "        actions = [\n",
    "            action_re.match(a)\n",
    "            for a in result.split('\\n')\n",
    "            if action_re.match(a)\n",
    "        ]\n",
    "        if actions:\n",
    "            action, action_input = actions[0].groups()\n",
    "            print(\" -- 실행중: {} {}\".format(action, action_input))\n",
    "            observation = known_actions[action](action_input)\n",
    "            print(\"Observation:\", observation)\n",
    "            next_prompt = \"Observation: {}\".format(observation)\n",
    "        else:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "UZdyuathngUz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 전우치와 홍길동의 전화번호를 먼저 찾아야 한다. 이를 위해 search_number 작업을 사용해야 한다. \n",
      "\n",
      "Action: search_number: 전우치\n",
      "PAUSE\n",
      " -- 실행중: search_number 전우치\n",
      "Observation: 010-1234-5678\n",
      "Thought: 전우치의 전화번호를 찾았으니, 이제 홍길동의 전화번호를 찾기 위해 search_number 작업을 다시 사용해야 한다.\n",
      "\n",
      "Action: search_number: 홍길동\n",
      "PAUSE\n",
      " -- 실행중: search_number 홍길동\n",
      "Observation: 010-4539-2918\n",
      "Thought: 전우치와 홍길동의 전화번호를 모두 찾았으니, 이제 두 사람에게 메시지를 보내야 한다. 먼저 전우치에게 메시지를 보내고, 그 다음 홍길동에게 메시지를 보내는 작업을 수행하겠다.\n",
      "\n",
      "Action: send_message: 010-1234-5678\n",
      "PAUSE\n",
      " -- 실행중: send_message 010-1234-5678\n",
      "Observation: 010-1234-5678에 메시지를 성공적으로 보냈습니다.\n",
      "Thought: 전우치에게 메시지를 성공적으로 보냈으니, 이제 홍길동에게 메시지를 보내는 작업을 수행하겠다.\n",
      "\n",
      "Action: send_message: 010-4539-2918\n",
      "PAUSE\n",
      " -- 실행중: send_message 010-4539-2918\n",
      "Observation: 010-4539-2918에 메시지를 성공적으로 보냈습니다.\n",
      "Answer: 전우치와 홍길동에게 메시지를 성공적으로 보냈습니다.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"전우치와 홍길동에게 메시지 보내 줘.\"\"\"\n",
    "query(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yjVCEDz_2iK"
   },
   "source": [
    "<br><br><br>\n",
    "# LangChain에서 Tool 사용하기\n",
    "\n",
    "이제, 해당 기능을 LangChain에서 구현해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGv8IR1n_2iK"
   },
   "source": [
    "총 4개의 툴을 사용합니다.\n",
    "\n",
    "1. wiki : 위키피디아 쿼리 검색 툴\n",
    "2. tavily : TavilyAI 웹 검색 툴\n",
    "3. repl_tool : Python REPL 실행 툴\n",
    "4. multiply : 단순 곱하기 커스텀 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "62b-4iUG_2iK"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-4o-mini', max_tokens=1024, temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUQffEYW_2iK"
   },
   "source": [
    "Tool 1: Wikipedia 검색 툴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "dlcYIYRS_2iK"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=3, doc_content_chars_max=5000)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper) # 위키피디아 쿼리 검색 툴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "2iCqf98j_2iK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /opt/anaconda3/envs/LLM/lib/python3.10/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: Artificial intelligence\n",
      "Summary: Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\n",
      "High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\n",
      "Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performed by a human on an at least equal level—is among the field's long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\n",
      "Artificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture, and by the early 2020s many billions of dollars were being invested in AI and the field experienced rapid ongoing progress in what has become known as the AI boom. The emergence of advanced generative AI in the midst of the AI boom and its ability to create and modify content exposed several unintended consequences and harms in the present and raised concerns about the risks of AI and its long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n",
      "\n",
      "Page: OpenAI\n",
      "Summary: OpenAI, Inc. is an American artificial intelligence (AI) research organization founded in December 2015 and headquartered in San Francisco, California. It aims to develop \"safe and beneficial\" artificial general intelligence (AGI), which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\". As a leading organization in the ongoing AI boom, OpenAI is known for the GPT family of large language models, the DALL-E series of text-to-image models, and a text-to-video model named Sora. Its release of ChatGPT in November 2022 has been credited with catalyzing widespread interest in generative AI.\n",
      "The organization consists of the non-profit OpenAI, Inc., registered in Delaware, and its for-profit subsidiary introduced in 2019, OpenAI Global, LLC. Its stated mission is to ensure that AGI \"benefits all of humanity\". Microsoft owns roughly 49% of OpenAI's equity, having invested US$13 billion. It also provides computing resources to OpenAI through its cloud platform, Microsoft Azure.\n",
      "In 2023 and 2024, OpenAI faced multiple lawsuits for alleged copyright infringement against authors and media companies whose work was used to train some of OpenAI's products. In November 2023, OpenAI's board removed Sam Altman as CEO, citing a lack of confidence in him, but reinstated him five days later following a reconstruction of the board. Throughout 2024, roughly half of then-employed AI safety researchers left OpenAI, citing the company's prominent role in an industry-wide problem.\n"
     ]
    }
   ],
   "source": [
    "print(wiki.invoke({\"query\": \"A.I\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUPAXX2-_2iK"
   },
   "source": [
    "Tavily: 웹 검색 툴   \n",
    "\n",
    "Tavily AI(https://app.tavily.com/home) 는 검색 결과에 AI 기반 요약을 포함하며,    \n",
    " 월 1,000개의 API 호출을 무료로 지원합니다.\n",
    "\n",
    "- 네이버/구글/유튜브 검색을 지원하는  SerpAPI(https://serpapi.com/)    \n",
    "(무료 라이센스 월 150회 검색)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "kH7JtFWi_2iL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "env_path = Path(\"/Users/blueno/UNO/SKALA/SKALA/.env\")\n",
    "load_dotenv(dotenv_path=env_path, override=True)\n",
    "\n",
    "# 환경 변수 확인\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "tavily = TavilySearchResults(max_results = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "yuXUoiOm_2iL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://www.anthropic.com/news/claude-3-5-sonnet', 'content': 'Introducing Claude 3.5 Sonnet \\\\ Anthropic Claude Claude 3.5 Sonnet Claude 3.5 Sonnet raises the industry bar for intelligence, outperforming competitor models and Claude 3 Opus on a wide range of evaluations, with the speed and cost of our mid-tier model, Claude 3 Sonnet. This performance boost, combined with cost-effective pricing, makes Claude 3.5 Sonnet ideal for complex tasks such as context-sensitive customer support and orchestrating multi-step workflows. Claude 3.5 Sonnet is our strongest vision model yet, surpassing Claude 3 Opus on standard vision benchmarks. It’s just the beginning of a broader vision for Claude.ai, which will soon expand to support team collaboration. You can submit feedback on Claude 3.5 Sonnet directly in-product to inform our development roadmap and help our teams to improve your experience. Claude'}, {'url': 'https://ai.yale.edu/posts/2025-02-10-announcing-claude-35-sonnet-on-the-clarity-platform', 'content': 'Announcing Claude 3.5 Sonnet on the Clarity Platform | AI at Yale Announcing Claude 3.5 Sonnet on the Clarity Platform Claude 3.5 Sonnet is now available on the Clarity Platform, offering a new generative AI model that supports brainstorming, creative and academic writing, code generation, and more. The Clarity Platform now features Claude 3.5 Sonnet, an agent that generates text responses using Anthropic’s Claude 3.5 Sonnet model and images using DALL·E 3. The selection of AI models available within Clarity allows members of the Yale community to compare and evaluate different tools while exploring their practical applications. Because it is an agent within the Clarity Platform, Claude 3.5 Sonnet is appropriate for use with low, medium, and most high-risk data, except for Electronic Protected Health Information (ePHI).'}, {'url': 'https://www.anthropic.com/claude/sonnet', 'content': \"For developers interested in building custom AI solutions with Claude 3.5 Sonnet, it is available on the Anthropic API, Amazon Bedrock, and Google Cloud's Vertex AI. Claude 3.5 Sonnet is the first frontier AI model to reliably use computers in this way—albeit experimentally in public beta—and we expect the capability to improve over time. With the new Claude 3.5 Sonnet, we’re entering a new era of AI-powered DevSecOps. Across our use cases, we’re seeing 5-10% improvements over the previous version. The new Claude 3.5 Sonnet with computer use is a leap forward in autonomous AI. When should I use Claude 3.5 Sonnet? We recommend Claude 3.5 Sonnet for critical use cases where you want frontier intelligence, like customer-facing AI experiences.\"}, {'url': 'https://www.datacamp.com/blog/claude-sonnet-anthropic', 'content': 'Claude 3.5 Sonnet outperforms GPT-4o and Gemini Pro 1.5 in several benchmarks and introduces a cool new feature: Artifacts. Claude 3.5 Sonnet not only beats GPT-4o and Gemini 1.5 Pro in several benchmarks but also introduces a new awesome feature called Artifacts. Once activated, you can trigger the feature by asking Claude to generate content that can be displayed in an Artifact, such as code, data visualizations, or even mockups. What are Artifacts in Claude 3.5 Sonnet? Artifacts is a new feature in Claude 3.5 Sonnet that allows you to interact with and manipulate outputs from the model, such as code, text, or data, directly within the chat interface. How can I use Artifacts in Claude 3.5 Sonnet? Explore Claude Artifacts, a new way to work with AI-generated content.'}, {'url': 'https://www.snowflake.com/en/blog/anthropic-claude-sonnet-cortex-ai/', 'content': \"Build RAG and Agent-based AI Apps with Anthropic’s Claude 3.5 Sonnet in Snowflake Cortex AI Snowflake launched Cortex AI, a suite of integrated features and services that include fully managed LLM inference, fine-tuning and RAG for structured and unstructured data, to enable customers to quickly analyze unstructured data alongside their structured data and expedite the building of AI apps. Gaining access to Anthropic's industry-leading Claude 3.5 models within Snowflake Cortex AI empowers us to more quickly unlock value for our shared clients in a way that is secure and governed. Claude 3.5 Sonnet in Cortex AI makes it easy to build apps alongside your data with other features such as Streamlit (frontend development in Python) and Cortex Search (RAG engine with integrated embedding generation, vector management and hybrid search).\"}]\n"
     ]
    }
   ],
   "source": [
    "print(tavily.invoke('Claude 3.5 Sonnet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gx13u3yo_2iL"
   },
   "source": [
    "PythonREPL : 파이썬 코드 작성 및 실행 툴  \n",
    "\n",
    "\n",
    "PythonREPL은 Code Interpreter와 다르게, 로컬 환경에서 실행됩니다.   \n",
    "임의의 파이썬 코드를 실행할 수 있으므로, 실행에 주의가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "z72ks4P8_2iL"
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "python_repl = PythonREPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "p-z8e5mO_2iL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_code = \"for i in range(10): print(i)\"\n",
    "\n",
    "python_repl.run(example_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcCA0IeI_2iL"
   },
   "source": [
    "`python_repl.run` 은 아래와 같이 툴로 변환 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ujZtq2RE_2iL"
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "\n",
    "repl_tool = Tool(\n",
    "    name=\"python_repl\",\n",
    "    description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\",\n",
    "    func=python_repl.run,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "MAegQEyg_2iL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repl_tool.invoke({\"input\": example_code})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3EUVA56_2iP"
   },
   "source": [
    "커스텀 함수를 툴로 변환하는 것도 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "jMnqg0ce_2iP"
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(x:int, y:int) -> int:\n",
    "    \"x와 y를 입력받아, x와 y를 곱한 결과를 반환합니다.\"\n",
    "    return x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "_p9xdR7J_2iQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = {'x':10, 'y':99}\n",
    "\n",
    "multiply.invoke(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "labB_kjA_2iQ"
   },
   "source": [
    "위에서 만든 툴을 리스트로 묶고, LLM에 binding합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "TvOHmM7C_2iQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='multiply', description='x와 y를 입력받아, x와 y를 곱한 결과를 반환합니다.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x11af6b250>),\n",
       " WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=5000)),\n",
       " TavilySearchResults(api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'))),\n",
       " Tool(name='python_repl', description='A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.', func=<bound method PythonREPL.run of PythonREPL(globals={'__builtins__': {'__name__': 'builtins', '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\", '__package__': '', '__loader__': <class '_frozen_importlib.BuiltinImporter'>, '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in'), '__build_class__': <built-in function __build_class__>, '__import__': <built-in function __import__>, 'abs': <built-in function abs>, 'all': <built-in function all>, 'any': <built-in function any>, 'ascii': <built-in function ascii>, 'bin': <built-in function bin>, 'breakpoint': <built-in function breakpoint>, 'callable': <built-in function callable>, 'chr': <built-in function chr>, 'compile': <built-in function compile>, 'delattr': <built-in function delattr>, 'dir': <built-in function dir>, 'divmod': <built-in function divmod>, 'eval': <built-in function eval>, 'exec': <built-in function exec>, 'format': <built-in function format>, 'getattr': <built-in function getattr>, 'globals': <built-in function globals>, 'hasattr': <built-in function hasattr>, 'hash': <built-in function hash>, 'hex': <built-in function hex>, 'id': <built-in function id>, 'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x1037d8730>>, 'isinstance': <built-in function isinstance>, 'issubclass': <built-in function issubclass>, 'iter': <built-in function iter>, 'aiter': <built-in function aiter>, 'len': <built-in function len>, 'locals': <built-in function locals>, 'max': <built-in function max>, 'min': <built-in function min>, 'next': <built-in function next>, 'anext': <built-in function anext>, 'oct': <built-in function oct>, 'ord': <built-in function ord>, 'pow': <built-in function pow>, 'print': <built-in function print>, 'repr': <built-in function repr>, 'round': <built-in function round>, 'setattr': <built-in function setattr>, 'sorted': <built-in function sorted>, 'sum': <built-in function sum>, 'vars': <built-in function vars>, 'None': None, 'Ellipsis': Ellipsis, 'NotImplemented': NotImplemented, 'False': False, 'True': True, 'bool': <class 'bool'>, 'memoryview': <class 'memoryview'>, 'bytearray': <class 'bytearray'>, 'bytes': <class 'bytes'>, 'classmethod': <class 'classmethod'>, 'complex': <class 'complex'>, 'dict': <class 'dict'>, 'enumerate': <class 'enumerate'>, 'filter': <class 'filter'>, 'float': <class 'float'>, 'frozenset': <class 'frozenset'>, 'property': <class 'property'>, 'int': <class 'int'>, 'list': <class 'list'>, 'map': <class 'map'>, 'object': <class 'object'>, 'range': <class 'range'>, 'reversed': <class 'reversed'>, 'set': <class 'set'>, 'slice': <class 'slice'>, 'staticmethod': <class 'staticmethod'>, 'str': <class 'str'>, 'super': <class 'super'>, 'tuple': <class 'tuple'>, 'type': <class 'type'>, 'zip': <class 'zip'>, '__debug__': True, 'BaseException': <class 'BaseException'>, 'Exception': <class 'Exception'>, 'TypeError': <class 'TypeError'>, 'StopAsyncIteration': <class 'StopAsyncIteration'>, 'StopIteration': <class 'StopIteration'>, 'GeneratorExit': <class 'GeneratorExit'>, 'SystemExit': <class 'SystemExit'>, 'KeyboardInterrupt': <class 'KeyboardInterrupt'>, 'ImportError': <class 'ImportError'>, 'ModuleNotFoundError': <class 'ModuleNotFoundError'>, 'OSError': <class 'OSError'>, 'EnvironmentError': <class 'OSError'>, 'IOError': <class 'OSError'>, 'EOFError': <class 'EOFError'>, 'RuntimeError': <class 'RuntimeError'>, 'RecursionError': <class 'RecursionError'>, 'NotImplementedError': <class 'NotImplementedError'>, 'NameError': <class 'NameError'>, 'UnboundLocalError': <class 'UnboundLocalError'>, 'AttributeError': <class 'AttributeError'>, 'SyntaxError': <class 'SyntaxError'>, 'IndentationError': <class 'IndentationError'>, 'TabError': <class 'TabError'>, 'LookupError': <class 'LookupError'>, 'IndexError': <class 'IndexError'>, 'KeyError': <class 'KeyError'>, 'ValueError': <class 'ValueError'>, 'UnicodeError': <class 'UnicodeError'>, 'UnicodeEncodeError': <class 'UnicodeEncodeError'>, 'UnicodeDecodeError': <class 'UnicodeDecodeError'>, 'UnicodeTranslateError': <class 'UnicodeTranslateError'>, 'AssertionError': <class 'AssertionError'>, 'ArithmeticError': <class 'ArithmeticError'>, 'FloatingPointError': <class 'FloatingPointError'>, 'OverflowError': <class 'OverflowError'>, 'ZeroDivisionError': <class 'ZeroDivisionError'>, 'SystemError': <class 'SystemError'>, 'ReferenceError': <class 'ReferenceError'>, 'MemoryError': <class 'MemoryError'>, 'BufferError': <class 'BufferError'>, 'Warning': <class 'Warning'>, 'UserWarning': <class 'UserWarning'>, 'EncodingWarning': <class 'EncodingWarning'>, 'DeprecationWarning': <class 'DeprecationWarning'>, 'PendingDeprecationWarning': <class 'PendingDeprecationWarning'>, 'SyntaxWarning': <class 'SyntaxWarning'>, 'RuntimeWarning': <class 'RuntimeWarning'>, 'FutureWarning': <class 'FutureWarning'>, 'ImportWarning': <class 'ImportWarning'>, 'UnicodeWarning': <class 'UnicodeWarning'>, 'BytesWarning': <class 'BytesWarning'>, 'ResourceWarning': <class 'ResourceWarning'>, 'ConnectionError': <class 'ConnectionError'>, 'BlockingIOError': <class 'BlockingIOError'>, 'BrokenPipeError': <class 'BrokenPipeError'>, 'ChildProcessError': <class 'ChildProcessError'>, 'ConnectionAbortedError': <class 'ConnectionAbortedError'>, 'ConnectionRefusedError': <class 'ConnectionRefusedError'>, 'ConnectionResetError': <class 'ConnectionResetError'>, 'FileExistsError': <class 'FileExistsError'>, 'FileNotFoundError': <class 'FileNotFoundError'>, 'IsADirectoryError': <class 'IsADirectoryError'>, 'NotADirectoryError': <class 'NotADirectoryError'>, 'InterruptedError': <class 'InterruptedError'>, 'PermissionError': <class 'PermissionError'>, 'ProcessLookupError': <class 'ProcessLookupError'>, 'TimeoutError': <class 'TimeoutError'>, 'open': <built-in function open>, 'copyright': Copyright (c) 2001-2023 Python Software Foundation.\n",
       " All Rights Reserved.\n",
       " \n",
       " Copyright (c) 2000 BeOpen.com.\n",
       " All Rights Reserved.\n",
       " \n",
       " Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
       " All Rights Reserved.\n",
       " \n",
       " Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
       " All Rights Reserved., 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
       "     for supporting Python development.  See www.python.org for more information., 'license': Type license() to see the full license text, 'help': Type help() for interactive help, or help(object) for help about object., 'execfile': <function execfile at 0x103876b00>, 'runfile': <function runfile at 0x1039c55a0>, '__IPYTHON__': True, 'display': <function display at 0x10283a290>, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x103be2470>>}}, locals={'i': 9})>)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [multiply, wiki, tavily, repl_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "eww24kgu_2iQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x1194b9b70>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1194bbc40>, root_client=<openai.OpenAI object at 0x118e58940>, root_async_client=<openai.AsyncOpenAI object at 0x1194b9bd0>, model_name='gpt-4o-mini', temperature=0.1, model_kwargs={}, openai_api_key=SecretStr('**********'), max_tokens=1024), kwargs={'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'x와 y를 입력받아, x와 y를 곱한 결과를 반환합니다.', 'parameters': {'properties': {'x': {'type': 'integer'}, 'y': {'type': 'integer'}}, 'required': ['x', 'y'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'python_repl', 'description': 'A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)\n",
    "llm_with_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWVSicuF_2iQ"
   },
   "source": [
    "이제 invoke를 통해 툴을 사용하도록 유도해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "zWO3ElzR_2iQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_MhaTzzbw0vRMia8kPLXlT3FN', 'function': {'arguments': '{\"x\":32,\"y\":7}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 244, 'total_tokens': 262, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3e5927e4-d614-4bc3-a6dd-7ba8a33b226a-0', tool_calls=[{'name': 'multiply', 'args': {'x': 32, 'y': 7}, 'id': 'call_MhaTzzbw0vRMia8kPLXlT3FN', 'type': 'tool_call'}], usage_metadata={'input_tokens': 244, 'output_tokens': 18, 'total_tokens': 262, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"32 * 7이 뭐야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "iqt0Yuva_2iQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_rBsYarFCJzpcoi2MZA3UuU5x', 'function': {'arguments': '{\"query\":\"양자 컴퓨터\"}', 'name': 'wikipedia'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 246, 'total_tokens': 263, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b33dd7ef-5d75-4f0a-83d6-3e2c1bd3a484-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': '양자 컴퓨터'}, 'id': 'call_rBsYarFCJzpcoi2MZA3UuU5x', 'type': 'tool_call'}], usage_metadata={'input_tokens': 246, 'output_tokens': 17, 'total_tokens': 263, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"양자 컴퓨터의 정의가 뭐야?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSLWfy2y_2iQ"
   },
   "source": [
    "content 대신 tool_calls 가 생성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "q79PRxGj_2iQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'x': 32, 'y': 7},\n",
       "  'id': 'call_o1pesOzz0ISDUKeC3NDvQbAB',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"32 * 7이 뭐야?\").tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "yxW_7x11_2iQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'wikipedia',\n",
       "  'args': {'query': '양자 컴퓨터'},\n",
       "  'id': 'call_UxXhF5yrTCMfNcTT2DS2uZkc',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"양자 컴퓨터의 정의가 뭐야?\").tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "HrKvAJzx_2iQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke(llm_with_tools.invoke(\"32 * 7이 뭐야?\").tool_calls[0]['args'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "lKwiKzkG_2iQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No good Wikipedia Search Result was found'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.invoke(llm_with_tools.invoke(\"양자 컴퓨터의 정의가 뭐야?\").tool_calls[0]['args'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No6-WbbhngUz"
   },
   "source": [
    "## LangChain Agent 만들기    \n",
    "\n",
    "위 Tool Calling의 결과를 바로 전달하여, 결과를 수행하는 에이전트를 만들어 보겠습니다.    \n",
    "\n",
    "RAG에서 사용했던 Retriever도 같이 활용하여, 강의자료와 웹 검색을 병행하는 에이전트를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "O8xMH4_8izzP"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "aclDWrqeirn-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39662\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "path_material = './data/attention.pdf'\n",
    "\n",
    "# 비밀번호 포함된 PDF 열기\n",
    "try:\n",
    "    loader = PyPDFLoader(path_material,password=\"your password\")\n",
    "    pages = loader.load()\n",
    "except:\n",
    "    loader = PyPDFLoader(path_material)\n",
    "    pages = loader.load()\n",
    "\n",
    "\n",
    "# 하나의 코퍼스에 합치기\n",
    "\n",
    "corpus = Document(page_content='')\n",
    "for page in pages:\n",
    "    corpus.page_content+=(page.page_content) + '\\n---\\n'\n",
    "\n",
    "print(len(corpus.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "WYDpr4Se37dM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "# 0~1000, 900~1900, 1800~2700, ...\n",
    "\n",
    "chunks = text_splitter.split_documents([corpus])\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "QBCSHCzM3Org"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fn/7bjmjvmn2d30b47j1yfz_5jm0000gn/T/ipykernel_96654/389126667.py:3: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  Chroma().delete_collection()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embeddings = OpenAIEmbeddings(model = 'text-embedding-3-large')\n",
    "\n",
    "Chroma().delete_collection()\n",
    "vector_store = Chroma.from_documents(chunks, embeddings)\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxhvF7l9ngU0"
   },
   "source": [
    "`create_retriever_tool`을 이용해 Retriever를 툴로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "DgZdFPpzngU0"
   },
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "search_material = create_retriever_tool(retriever,\"LLM 교재 검색\",\n",
    "                                        \"LLM(거대 언어 모델) 교육의 강의자료를 검색합니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGVL5NJKngU0"
   },
   "source": [
    "Tavily API는 그대로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Yc9W_xynngU0"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily = TavilySearchResults(max_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuyorirUngU0"
   },
   "source": [
    "Wikipedia 툴도 그대로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "vQcTjdpUngU0"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=3, doc_content_chars_max=1000)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mt_zAvUh_2iS"
   },
   "source": [
    "PythonREPL 툴도 그대로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "m7P-Zgaq_2iS"
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "python_repl = PythonREPL()\n",
    "repl_tool = Tool(\n",
    "    name=\"python_repl\",\n",
    "    description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\",\n",
    "    func=python_repl.run,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdadOZtN_2iS"
   },
   "source": [
    "Multiply 툴도 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "qcfwNrNw_2iS"
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(x:int, y:int) -> int:\n",
    "    \"x와 y를 입력받아, x와 y를 곱한 결과를 반환합니다.\"\n",
    "    return x*y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiB9XUb6_2iS"
   },
   "source": [
    "이번 실습에서는 Structured Chat Agent를 사용합니다.   \n",
    "ReAct(강의자료 참조) 의 원리에, json 형식의 출력을 활용한 방법입니다.   \n",
    "\n",
    "(https://python.langchain.com/v0.1/docs/modules/agents/agent_types/structured_chat/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "MGvzDWn7ngU0"
   },
   "outputs": [],
   "source": [
    "agent_prompt = ChatPromptTemplate.from_messages(messages=[\n",
    "                                  ('system','''\n",
    "최대한 정확히 질문에 답변하세요. 당신은 다음의 툴을 사용할 수 있습니다:\n",
    "{tools}\n",
    "\n",
    "action 키 (tool name)와 action_input 키를 포함하는 json 형태로 출력하세요.\n",
    "\n",
    "action의 값은 \"Final Answer\" 또는 {tool_names} 중 하나여야 합니다.\n",
    "반드시 하나의 json 형태만 출력하세요. 다음은 예시입니다.\n",
    "```\n",
    "{{\n",
    "\n",
    "  \"action\": $TOOL_NAME,\n",
    "\n",
    "  \"action_input\": $INPUT\n",
    "\n",
    "}}\n",
    "```\n",
    "\n",
    "아래의 포맷으로 답변하세요.:\n",
    "\n",
    "Question: 최종적으로 해결해야 하는 질문 혹은 지시사항\n",
    "Thought: 무엇을 해야 하는지를 항상 떠올리세요.\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Observation: 액션의 실행 결과\n",
    "... (이 Thought/Action/Observation 은 10번 이내로 반복될 수 있습니다.)\n",
    "\n",
    "Thought: 이제 답을 알겠다!\n",
    "Action:\n",
    "```\n",
    "{{\n",
    "  \"action\": \"Final Answer\",\n",
    "  \"action_input\": \"Final response to human(Must be Korean)\"\n",
    "}}\n",
    "\n",
    "주어진 포맷을 잘 지켜야 하며, 한 번에 Thought와 Action을 동시에 쓰지 마세요.\n",
    "Question, Thought, Action, Observation의 출력 뒤에는 항상 줄을 바꾸세요.\n",
    "\n",
    "이제 입력이 주어집니다.json blob 형태로 출력해야 함을 명심하고,\n",
    "Thought의 경우에는 항상 Thought: 로 시작해야 합니다.\n",
    "포맷은 Action:```$JSON_BLOB``` 이후 Observation 입니다.\n",
    "'''),\n",
    "\n",
    "('user','''Question: {input}\n",
    "Thought: {agent_scratchpad}''')])\n",
    "# agent_scratchpad : 각 스텝의 결과를 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "UZa7ALt4ngU0"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-4o-mini', max_tokens=1024, temperature=0.1)\n",
    "tools = [search_material, wiki, tavily, repl_tool, multiply]\n",
    "\n",
    "agent = create_structured_chat_agent(llm, tools, agent_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bc-DCspXB_O5"
   },
   "source": [
    "agent와 tool을 넣어 AgentExecutor를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "bcqWqhaOB_O5"
   },
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "P04EeTc7B_O5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: LLM 파인튜닝에 대한 정보를 찾아야 한다. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"LLM fine-tuning\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Fine-tuning (deep learning)\n",
      "Summary: In deep learning, fine-tuning is an approach to transfer learning in which the parameters of a pre-trained neural network model are trained on new data. Fine-tuning can be done on the entire neural network, or on only a subset of its layers, in which case the layers that are not being fine-tuned are \"frozen\" (i.e., not changed during backpropagation). A model may also be augmented with \"adapters\" that consist of far fewer parameters than the original model, and fine-tuned in a parameter-efficient way by tuning the weights of the adapters and leaving the rest of the model's weights frozen.\n",
      "For some architectures, such as convolutional neural networks, it is common to keep the earlier layers (those closest to the input layer) frozen, as they capture lower-level features, while later layers often discern high-level features that can be more related to the task that the model is trained on.\n",
      "Models that are pre-trained on large, general corpora are\u001b[0m\u001b[32;1m\u001b[1;3mThought: LLM 파인튜닝은 사전 훈련된 신경망 모델의 매개변수를 새로운 데이터에 맞게 조정하는 과정이다. 이 정보를 바탕으로 LLM 파인튜닝에 대한 설명을 정리할 수 있다.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"LLM 파인튜닝은 사전 훈련된 신경망 모델의 매개변수를 새로운 데이터에 맞게 조정하는 과정입니다. 이 과정에서는 전체 신경망을 조정할 수도 있고, 일부 레이어만 조정할 수도 있습니다. 조정하지 않는 레이어는 '동결'되어 변경되지 않습니다. 또한, 모델에 '어댑터'를 추가하여 매개변수를 효율적으로 조정할 수 있습니다.\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'LLM 파인튜닝이 뭐야?',\n",
       " 'output': \"LLM 파인튜닝은 사전 훈련된 신경망 모델의 매개변수를 새로운 데이터에 맞게 조정하는 과정입니다. 이 과정에서는 전체 신경망을 조정할 수도 있고, 일부 레이어만 조정할 수도 있습니다. 조정하지 않는 레이어는 '동결'되어 변경되지 않습니다. 또한, 모델에 '어댑터'를 추가하여 매개변수를 효율적으로 조정할 수 있습니다.\"}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"LLM 파인튜닝이 뭐야?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "f7WeawXq_2iT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m레오나르도 디카프리오의 출생년도를 찾아야 합니다. 그 후, 각 숫자를 순서대로 곱할 것입니다. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"레오나르도 디카프리오\"\n",
      "}\n",
      "```\u001b[0m\u001b[33;1m\u001b[1;3mNo good Wikipedia Search Result was found\u001b[0m\u001b[32;1m\u001b[1;3mThought: 위키피디아에서 레오나르도 디카프리오의 출생년도 정보를 찾지 못했습니다. 다른 방법으로 검색해 보겠습니다. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"tavily_search_results_json\",\n",
      "  \"action_input\": \"레오나르도 디카프리오 출생년도\"\n",
      "}\n",
      "```\u001b[0m\u001b[38;5;200m\u001b[1;3m[{'url': 'https://namu.wiki/w/%EB%A0%88%EC%98%A4%EB%82%98%EB%A5%B4%EB%8F%84%20%EB%94%94%EC%B9%B4%ED%94%84%EB%A6%AC%EC%98%A4', 'content': '본명. Leonardo Wilhelm DiCaprio (레오나르도 빌헬름 디카프리오)[1] ; 출생. 1974년 11월 11일 (50세) ; 출생 · 캘리포니아 주 로스앤젤레스 할리우드.'}, {'url': 'https://namu.wiki/w/%EB%A0%88%EC%98%A4%EB%82%98%EB%A5%B4%EB%8F%84%20%EB%94%94%EC%B9%B4%ED%94%84%EB%A6%AC%EC%98%A4?uuid=37452b28-9a9b-409a-ab68-2b27a5cdab3d', 'content': '본명. Leonardo Wilhelm DiCaprio (레오나르도 빌헬름 디카프리오)[1] ; 출생. 1974년 11월 11일 (50세) ; 출생 · 미국 캘리포니아주 로스앤젤레스 할리우드.'}, {'url': 'https://ko.wikipedia.org/wiki/%EB%A0%88%EC%98%A4%EB%82%98%EB%A5%B4%EB%8F%84_%EB%94%94%EC%B9%B4%ED%94%84%EB%A6%AC%EC%98%A4', 'content': '레오나르도 디카프리오 ; 1974년 11월 11일(1974-11-11)(50세) 미국 캘리포니아주 할리우드 · 미국 · 배우, 영화 제작자, 환경 운동가 · 1989년~현재.'}, {'url': 'https://m.blog.naver.com/jhyuna0812/221403708891', 'content': 'Leonardo DiCaprio. (레오나르도 디카프리오). 본명: Leonardo Wilhelm DiCaprio. 출생: 1974년 11월 11일, 미국. 직업: 배우.'}, {'url': 'https://m.blog.naver.com/jaemoonlim/221773811410', 'content': '출생. 1974년 11월 11일 LA에서 태어났다. 어머니 이멀린 디카프리오 함께. 디카프리오 부모, 조지 와 이멀린 은 이탈리아 피렌체의 우피치 미술관에서.'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: 레오나르도 디카프리오의 출생년도는 1974년입니다. 이제 각 숫자를 순서대로 곱해보겠습니다. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"multiply\",\n",
      "  \"action_input\": {\n",
      "    \"x\": 1,\n",
      "    \"y\": 9\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\u001b[33;1m\u001b[1;3m9\u001b[0m\u001b[32;1m\u001b[1;3mThought: 첫 번째 숫자 1과 두 번째 숫자 9를 곱한 결과는 9입니다. 이제 세 번째 숫자 7과 4를 곱해보겠습니다. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"multiply\",\n",
      "  \"action_input\": {\n",
      "    \"x\": 9,\n",
      "    \"y\": 7\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\u001b[33;1m\u001b[1;3m63\u001b[0m\u001b[32;1m\u001b[1;3mThought: 이제 마지막 숫자 4와 63을 곱해보겠습니다. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"multiply\",\n",
      "  \"action_input\": {\n",
      "    \"x\": 63,\n",
      "    \"y\": 4\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\u001b[33;1m\u001b[1;3m252\u001b[0m\u001b[32;1m\u001b[1;3mThought: 이제 최종 결과를 알겠다! 레오나르도 디카프리오의 출생년도 1974의 각 숫자를 곱한 결과는 252이다. \n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"레오나르도 디카프리오의 출생년도 1974의 각 숫자를 곱한 결과는 252입니다.\"\n",
      "} \n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '레오나르도 디카프리오의 출생년도를 찾은 뒤, 각 숫자를 순서대로 곱해줘.',\n",
       " 'output': '레오나르도 디카프리오의 출생년도 1974의 각 숫자를 곱한 결과는 252입니다.'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({'input':\"레오나르도 디카프리오의 출생년도를 찾은 뒤, 각 숫자를 순서대로 곱해줘.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "7iTawofTNg3J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: 현재 시점에서 2025년 3월의 chatbot arena 1위 모델에 대한 정보를 찾아야 한다. 최신 정보를 확인하기 위해 검색을 진행하겠다.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"tavily_search_results_json\",\n",
      "  \"action_input\": \"2025년 3월 chatbot arena 1위 모델\"\n",
      "}\n",
      "```\u001b[0m\u001b[38;5;200m\u001b[1;3m[{'url': 'http://www.ainet.link/18969', 'content': \"두 모델 모두 AIME'24, GPQA, LiveCodeBench 벤치마크에서 1위를 차지했으며, Grok-3 초기 버전은 Chatbot Arena 에서 1위를 차지했습니다 . 이 모델\"}, {'url': 'https://blog.naver.com/allsix6/223764755144?fromRss=true&trackingCode=rss', 'content': '\"Grok 3는 세계 최고의 새로운 모델입니다.\" \\u200b. \"Grok 3는 Chatbot Arena에서 큰 격차로 1위를 차지했으며 사전 훈련 및 추론 평가에서 인상적인 점수'}, {'url': 'https://www.chaincatcher.com/ko/article/2164826', 'content': '전해진 바에 따르면, DeepSeek의 오픈 소스 모델 DeepSeek-R1은 Chatbot Arena 종합 차트에서 3위를 기록하며 OpenAI의 최고 추론 모델과 나란히 있습니다'}, {'url': 'https://www.facebook.com/groups/chatgptkr/posts/1546267226219640/', 'content': '40만명이 넘는 사람들의 선호도 투표를 모아 Elo 랭킹 시스템으로 LLM을 순위화했습니다. 부연 설명: • LMSYS Chatbot Arena Leaderboard 는 대규모 언어'}, {'url': 'https://lmarena.ai/', 'content': 'GLM-4: Next-Gen Foundation Model by Zhipu AI, Jamba 1.5: Jamba by AI21 Labs, Gemma 2: Gemma 2 by Google ; Claude: Claude by Anthropic, Nemotron-4 340B: Cutting-'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: 검색 결과에 따르면, 2025년 3월 현재 Chatbot Arena에서 1위 모델은 \"Grok 3\"이다. 이 모델은 여러 벤치마크에서 높은 점수를 기록하며 큰 격차로 1위를 차지했다고 한다.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"2025년 3월 현재 Chatbot Arena 1위 모델은 Grok 3입니다.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '2025년 3월 현재 chatbot arena 1위 모델이 뭐야?',\n",
       " 'output': '2025년 3월 현재 Chatbot Arena 1위 모델은 Grok 3입니다.'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"2025년 3월 현재 chatbot arena 1위 모델이 뭐야?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "DjOvHU0UNNoN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to search for the latest information regarding the best model in Chatbot Arena as of March 2025. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"tavily_search_results_json\",\n",
      "  \"action_input\": \"best model in Chatbot Arena March 2025\"\n",
      "}\n",
      "```\u001b[0m\u001b[38;5;200m\u001b[1;3m[{'url': 'https://manifold.markets/Bayesian/which-company-has-best-ai-model-end', 'content': 'Resolution is based on the chatbot arena LLM leaderboard (https://lmarena.ai), specifically the company with the highest Arena Score in the Overall category'}, {'url': 'https://www.threads.net/@camillagimenez/post/DGPuEvwuaY1', 'content': '“Grok-3 is the first model *ever* to score over 1400 on Chatbot Arena and outperforms the best publicly available reasoning models from OpenAI'}, {'url': 'https://www.metaculus.com/questions/34244/on-mar-1-25-highest-avg-win-shown-at-arena-leaderboard/', 'content': 'Specifically, we will mouseover the highest win rate model displayed under \"Figure 2: Average Win Rate Against All Other Models (Assuming'}, {'url': 'https://www.metaculus.com/questions/31326/openai-tops-chatbot-arena-at-end-2025/', 'content': 'Will OpenAI top the Chatbot Arena Leaderboard on December 31, 2025? Will OpenAI top the Chatbot Arena Leaderboard on December 31, 2025? Make a Prediction Sign Up to Predict #### Will any AI system beat most teams of human pros in a forecasting tournament before January 1, 2030? 65%#### Will there be a frontier open-source AI model on January 1 of the following years?#### Will AI capabilities plateau with the next generation (GPT-5, etc.) of language models? #### Will any AI system beat most teams of human pros in a forecasting tournament before January 1, 2030? 65%#### Will there be a frontier open-source AI model on January 1 of the following years?#### Will AI capabilities plateau with the next generation (GPT-5, etc.) of language models?'}, {'url': 'https://www.unite.ai/best-large-language-models-llms/', 'content': \"Announced in February 2024 and made available for public preview in May 2024, Google's Gemini 1.5 Pro also represented a significant advancement in AI capabilities, offering improved performance across various tasks and modalities. Grok-2 represents a significant advancement in AI technology, offering improved performance across various tasks and introducing new capabilities like image generation. These LLMs, including Claude 3, GPT-4o, Llama 3.1, Gemini 1.5 Pro, and Grok-2, represent the pinnacle of AI language understanding and generation. *   5 Best Open Source LLMs (February 2025) *   10 Best AI Code Generators (February 2025) *   10 Best AI Tools for Business (February 2025) *   10 Best AI Tools for Education (February 2025) *   10 Best Python Libraries for Natural Language Processing *   6 Best Machine Learning & AI Books of All Time (February 2025)\"}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: I have found some relevant information regarding the best model in Chatbot Arena as of March 2025. It appears that \"Grok-3\" is the first model to score over 1400 on the Chatbot Arena, outperforming other models. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"2025년 3월 Chatbot Arena에서 가장 좋은 모델은 'Grok-3'입니다. 이 모델은 Chatbot Arena에서 1400점을 초과한 최초의 모델로, OpenAI의 최고의 공개 추론 모델들을 능가합니다.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the best model in Chatbot Arena in 2025 March?',\n",
       " 'output': \"2025년 3월 Chatbot Arena에서 가장 좋은 모델은 'Grok-3'입니다. 이 모델은 Chatbot Arena에서 1400점을 초과한 최초의 모델로, OpenAI의 최고의 공개 추론 모델들을 능가합니다.\"}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"What is the best model in Chatbot Arena in 2025 March?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "hj5u6tyW_2iT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: 2025년 3월에 Chatbot Arena에서 가장 좋은 5개의 모델을 저장해야 합니다. 이를 위해 먼저 해당 모델들의 정보를 검색해야 합니다. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"tavily_search_results_json\",\n",
      "  \"action_input\": \"best 5 models in Chatbot Arena March 2025\"\n",
      "}\n",
      "```\u001b[0m\u001b[38;5;200m\u001b[1;3m[{'url': 'https://manifold.markets/Bayesian/which-company-has-best-ai-model-end?play=true', 'content': '(Chatbot Arena Leaderboard) | Manifold Resolution is based on the chatbot arena LLM leaderboard (https://lmarena.ai), specifically the company with the highest Arena Score in the Overall category without filters (without style control or show deprecated), at the end of March 31, 2025 11:59PM ET. 5 Comments25 Holders63 Trades jimWhich company has the best AI model in the WebDev Arena in 2025? BayesianWill the best AI model according to the Chatbot Arena Leaderboard be using Mixture-of-Depths, at the end of 2025? ( >\\\\= week)  LouisWhich company has the best AI model in the WebDev Arena in 2025? (>\\\\=week)  LouisWill the best AI model according to the Chatbot Arena Leaderboard be using Mixture-of-Depths, at the end of 2025?'}, {'url': 'https://www.unite.ai/best-large-language-models-llms/', 'content': \"Announced in February 2024 and made available for public preview in May 2024, Google's Gemini 1.5 Pro also represented a significant advancement in AI capabilities, offering improved performance across various tasks and modalities. Grok-2 represents a significant advancement in AI technology, offering improved performance across various tasks and introducing new capabilities like image generation. These LLMs, including Claude 3, GPT-4o, Llama 3.1, Gemini 1.5 Pro, and Grok-2, represent the pinnacle of AI language understanding and generation. *   5 Best Open Source LLMs (February 2025) *   10 Best AI Code Generators (February 2025) *   10 Best AI Tools for Business (February 2025) *   10 Best AI Tools for Education (February 2025) *   10 Best Python Libraries for Natural Language Processing *   6 Best Machine Learning & AI Books of All Time (February 2025)\"}, {'url': 'https://manifold.markets/topic/chatbot-arena-leaderboard', 'content': 'An AI model will rate higher than GPT-4-Turbo on the Chatbot Arena Leaderboard (OpenAI model or other) before May 2024.'}, {'url': 'https://www.metaculus.com/questions/31326/openai-tops-chatbot-arena-at-end-2025/', 'content': 'Will OpenAI top the Chatbot Arena Leaderboard on December 31, 2025? Will OpenAI top the Chatbot Arena Leaderboard on December 31, 2025? Make a Prediction Sign Up to Predict #### Will any AI system beat most teams of human pros in a forecasting tournament before January 1, 2030? 65%#### Will there be a frontier open-source AI model on January 1 of the following years?#### Will AI capabilities plateau with the next generation (GPT-5, etc.) of language models? #### Will any AI system beat most teams of human pros in a forecasting tournament before January 1, 2030? 65%#### Will there be a frontier open-source AI model on January 1 of the following years?#### Will AI capabilities plateau with the next generation (GPT-5, etc.) of language models?'}, {'url': 'https://openlm.ai/chatbot-arena/', 'content': '| Gemini-1.5-Flash-8B-001 | 1213 | 1208 |  |  | 37689 | Google | Proprietary | | Gemini-1.5-Flash-8B-Exp-0827 | 1205 | 1189 |  |  | 25344 | Google | Proprietary | | Reka-Flash-21B-online | 1156 | 1147 |  |  | 16023 | Reka AI | Proprietary | | Reka-Flash-21B | 1148 | 1141 |  | 73.5 | 25803 | Reka AI | Proprietary | | pplx-70B-online | 1078 | 1028 |  |  | 6890 | Perplexity AI | Proprietary | | Mistral-7B-Instruct-v0.2 | 1072 | 1074 | 12.57 |  | 20049 | Mistral | Apache-2.0 | | pplx-7B-online | 1044 | 1015 |  |  | 6338 | Perplexity AI | Proprietary | | OLMo-7B-instruct | 1016 | 1017 |  |  | 6501 | Allen AI | Apache-2.0 |'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: Chatbot Arena에서 2025년 3월에 가장 좋은 5개의 모델에 대한 정보를 찾았습니다. 다음으로 이 모델들의 이름을 정리하여 'data/models.txt' 파일에 저장해야 합니다. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"python_repl\",\n",
      "  \"action_input\": \"models = ['Gemini-1.5-Flash-8B-001', 'Gemini-1.5-Flash-8B-Exp-0827', 'Reka-Flash-21B-online', 'Reka-Flash-21B', 'pplx-70B-online']; with open('data/models.txt', 'w') as f: f.write('\\\\n'.join(models))\"\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3mSyntaxError('invalid syntax', ('<string>', 1, 133, \"models = ['Gemini-1.5-Flash-8B-001', 'Gemini-1.5-Flash-8B-Exp-0827', 'Reka-Flash-21B-online', 'Reka-Flash-21B', 'pplx-70B-online']; with open('data/models.txt', 'w') as f: f.write('\\\\n'.join(models))\\n\", 1, 137))\u001b[0m\u001b[32;1m\u001b[1;3mThought: Python 코드에서 문법 오류가 발생했습니다. 파일을 저장하는 코드를 수정하여 다시 시도해야 합니다. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"python_repl\",\n",
      "  \"action_input\": \"models = ['Gemini-1.5-Flash-8B-001', 'Gemini-1.5-Flash-8B-Exp-0827', 'Reka-Flash-21B-online', 'Reka-Flash-21B', 'pplx-70B-online']; open('data/models.txt', 'w').write('\\\\n'.join(models))\"\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThought: 이제 모델 정보를 파일에 저장하는 코드가 수정되었습니다. 다시 실행해 보겠습니다. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"python_repl\",\n",
      "  \"action_input\": \"models = ['Gemini-1.5-Flash-8B-001', 'Gemini-1.5-Flash-8B-Exp-0827', 'Reka-Flash-21B-online', 'Reka-Flash-21B', 'pplx-70B-online']; open('data/models.txt', 'w').write('\\\\n'.join(models))\"\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThought: 모델 정보를 파일에 저장하는 코드가 잘 실행되었는지 확인해야 합니다. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"2025년 3월 Chatbot Arena에서 가장 좋은 5개의 모델이 'data/models.txt' 파일에 저장되었습니다.\"\n",
      "} \n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"save the best 5 models in Chatbot Arena in 2025 March as 'data/models.txt'\",\n",
       " 'output': \"2025년 3월 Chatbot Arena에서 가장 좋은 5개의 모델이 'data/models.txt' 파일에 저장되었습니다.\"}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"save the best 5 models in Chatbot Arena in 2025 March as 'data/models.txt'\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KENPz11_2iT"
   },
   "source": [
    "LangChain Agent는 툴을 잘 사용하지만, 중간 개입이 어렵고    \n",
    "파싱 에러가 자주 발생한다는 단점이 있습니다.   \n",
    "(모델이 충분히 똑똑하지 못한 경우에는 더 불안정합니다.)\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TNj0WJ6ngVA"
   },
   "source": [
    "## LangGraph로 Agentic Application 만들기\n",
    "\n",
    "LangGraph를 사용하면, 훨씬 유연한 선택이 가능합니다.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czPC_0k3ngVB"
   },
   "source": [
    "Advanced RAG의 예시 중 하나인 Corrective RAG(CRAG)을 구현해 보겠습니다.\n",
    "\n",
    "CRAG은 Retrieval Evaluator를 이용하여, 검색된 Document를     \n",
    "`적합/부적합/불확실`로 분류하고, 웹 검색을 활용하여 이를 개선하는데요.\n",
    "\n",
    "\n",
    "이를 조금 단순화하여 적합/부적합의 형태로 분류하고,   \n",
    "Document 중 적합한 결과가 없으면 웹 서치를 수행하도록 작성해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TKtiykKngVB"
   },
   "source": [
    "![image](https://github.com/NotoriousH2/img_container/assets/4037207/dd334478-1284-44e1-bf4f-a40fa14ab986)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tc8tgqN6Q9Xw"
   },
   "source": [
    "## 1. Retrieval Grader\n",
    "Retriever의 결과물을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "TS6jwblGngVB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '강아지와 고양이 중 뇌세포 수가 누가 더 많은가요?',\n",
       " 'document': '6\\n---\\nlength n is smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[38] and byte-pair [31] representations. To improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in\\nthe input sequence centered around the respective output position. This would increase the maximum\\npath length to O(n/r). We plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k < ndoes not connect all pairs of input and output\\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\\nor O(logk(n)) in the case of dilated convolutions [ 18], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than',\n",
       " 'grade': '강아지와 고양이의 뇌세포 수를 비교하는 질문인데, 문서는 자연어 처리 모델의 기술적 세부사항과 관련된 내용을 다루고 있습니다. 따라서 이 문서는 질문에 대한 정보를 포함하고 있지 않습니다. [결과]: Not Relevant',\n",
       " 'score': 'No'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Retrieval Grader\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.schema.runnable import RunnableParallel\n",
    "\n",
    "\n",
    "# 'not relevant'가 있으면 'No'를 반환, 나머지 경우 'Yes' 반환\n",
    "def parse_relevance_score(response):\n",
    "    return 'No' if 'not relevant' in response['grade'].lower() else 'Yes'\n",
    "\n",
    "\n",
    "structured_llm_grader = llm\n",
    "\n",
    "# 평가 프롬프트\n",
    "system = \"\"\"당신은 주어진 [질문]과 검색된 [문서] 사이의 연관성을 판단해야 합니다.\n",
    "[질문]을 답변하기 위한 정보를 [문서]가 포함하고 있는지를 설명하세요.\n",
    "그 이후, [결과]에 'Relevant' 또는 'Not Relevant'를 출력하세요.\n",
    "다음은 예시 답변입니다.\n",
    "\n",
    "예시)\n",
    "[답변]: 이 질문은 공룡의 멸종 원인을 묻는 질문으로, 문서는 공룡과 관련이 없는 내용입니다. [결과]: Not Relevant\n",
    "\n",
    "[답변]: 이 질문은 프롬프트 엔지니어링의 장점을 묻는 질문인데, 문서는 프롬프트 엔지니어링에 대해 다루고 있습니다. [결과]: Relevant\n",
    "\n",
    "[답변]: 이 질문은 지구 온난화의 주요 원인을 묻는 질문으로, 문서는 중세 시대의 역사적 사건들에 대해 다루고 있습니다. [결과]: Not Relevant\n",
    "\n",
    "[답변]: 이 질문은 로마 제국의 멸망 원인을 묻는 질문으로, 문서는 로마 제국의 경제 구조와 사회적 변화에 대해 다루고 있습니다. [결과]: Relevant\n",
    "\n",
    "[답변]: 이 질문은 현대 인공지능의 윤리적 문제를 묻는 질문으로, 문서는 최신 영화 리뷰와 평점에 대해 다루고 있습니다. [결과]: Not Relevant\n",
    "\n",
    "시작\n",
    "\n",
    "[답변]:\"\"\"\n",
    "\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"[문서]: \\n\\n {document} \\n\\n [질문]: {question} [답변]: 이 질문은 \\n\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# question, doc, grade, score 순서로 출력하기\n",
    "\n",
    "retrieval_grader = RunnableParallel(\n",
    "    question = lambda x:x['question'],\n",
    "    document = lambda x:x['document'],\n",
    "    ).assign(grade = grade_prompt | structured_llm_grader | StrOutputParser()\n",
    "    ).assign(score=parse_relevance_score)\n",
    "\n",
    "question = \"강아지와 고양이 중 뇌세포 수가 누가 더 많은가요?\"\n",
    "docs = retriever.invoke(question)\n",
    "\n",
    "doc_txt = docs[1].page_content\n",
    "\n",
    "retrieval_grader.invoke({\"question\": question, \"document\": doc_txt})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZfmQCCETSPo"
   },
   "source": [
    "## 2. RAG-Chain\n",
    "\n",
    "Context와 Question을 바탕으로 질문에 답변합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "oVgB7xXJngVB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention은 쿼리와 키-값 쌍을 매핑하여 출력을 생성하는 함수로, 쿼리와 해당 키의 호환성 함수에 따라 가중치를 부여하여 값의 가중합을 계산합니다. Self-Attention은 같은 시퀀스 내의 서로 다른 위치를 연결하여 시퀀스의 표현을 계산하는 주의 메커니즘으로, 입력의 모든 위치가 이전 레이어의 모든 위치에 주의를 기울일 수 있도록 합니다. Transformer 모델에서는 Self-Attention을 사용하여 입력과 출력을 계산하며, 이는 RNN이나 합성곱을 사용하지 않고도 가능하게 합니다. Self-Attention은 다양한 작업에서 성공적으로 활용되고 있으며, 특히 읽기 이해, 요약, 텍스트 추론 등의 분야에서 효과적입니다.\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"user\", '''당신은 QA(Question-Answering)을 수행하는 Assistant입니다. 다음의 Context를 이용하여 Question에 답변하세요.\n",
    "최소 3문장에서 최대 5문장으로 답변하고, 정확한 답변을 제공하세요.\n",
    "만약 모든 Context를 다 확인해도 정보가 없다면, \"정보가 부족하여 답변할 수 없습니다.\"를 출력하세요.\n",
    "답변은 한국어로 작성하세요.\n",
    "---\n",
    "Context: {context}\n",
    "---\n",
    "Question: {question}''')])\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n---\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Context, Question은 다른 체인에서 전달되므로, prompt부터 구성\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "question = \"Attention과 Self-Attention에 대해 설명?\" # 컹컹 크르르르 크앙 컹컹컹 # 사람과 개의 뇌세포 수는 어떻게 다른가?\n",
    "docs = retriever.invoke(question)\n",
    "\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PN4n4aKoTrvc"
   },
   "source": [
    "## 3. Question Rewriter\n",
    "\n",
    "질문을 재구성하여 다시 검색할 수 있는 쿼리를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "GGFLaE8fngVB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Attention과 Self-Attention의 개념에 대해 자세히 설명해 주실 수 있나요?'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = \"\"\"당신은 주어진 질문을 재작성해야 합니다. 질문의 의미가 더 명확하게 드러나도록 Rewrite 하세요.\n",
    "영어를 한국어로 번역하지 마세요.\"\"\"\n",
    "\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"user\", \"원본 질문: {question} \\n 새로운 질문:\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Br9bcMDPngVC"
   },
   "source": [
    "Retrieval-Grader, RAG, Question Re-writer는 각각 LangChain으로 구성된 체인입니다.    \n",
    "이를 이용하여 LangGraph Agent를 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keKY7NBjngVC"
   },
   "source": [
    "# LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XU55UJVQngVC"
   },
   "source": [
    "langgraph에서는 `GraphState`의 형태로 Agent의 활동 상태를 정의합니다.   \n",
    "에이전트는 여러 개의 노드를 오가며 State에 상태값을 저장하고, 이를 체인에 전달하여 결과를 얻습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUXbqSRungVC"
   },
   "source": [
    "\n",
    "![image](https://github.com/NotoriousH2/img_container/assets/4037207/781ae921-426a-410b-888d-04e965e14794)\n",
    "\n",
    "\n",
    "Source: https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_crag.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rpfsK9BU0Bi"
   },
   "source": [
    "어플리케이션의 과정에서 값을 저장할 클래스 `CRAGState`를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "KqGhZ2BOngVC"
   },
   "outputs": [],
   "source": [
    "# typing : 변수 타입을 명시해줄 수 있음\n",
    "# TypeDict : Dict의 원소 명시\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class CRAGState(TypedDict):\n",
    "\n",
    "    question: str\n",
    "    # 질문\n",
    "    generation: str\n",
    "    # 생성 결과\n",
    "    needed_web_search: bool\n",
    "    # 웹 서치가 필요한지 판단\n",
    "\n",
    "    documents: List[str]\n",
    "    # Retrieval+ Web Search 결과 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gv7X-j64V3eq"
   },
   "source": [
    "LangGraph에서 각각의 기능들은 함수로 정의되는데, 이를 노드나 엣지로 표현합니다.    \n",
    "\n",
    "함수가 실행되는 경우, 위에서 구성한 `CRAGState`를 받아 해당 내용을 계속 수정하며 진행하게 됩니다.   \n",
    "함수의 Return은 Dict로 전달되는데, 이는 State의 값으로 업데이트됩니다.   \n",
    "위에서 만든 Chain을 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "26yTmWCYngVC"
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "# 질문이 들어오면 Retriever 실행\n",
    "def retrieve(state):\n",
    "    print(\"---검색---\")\n",
    "    question = state[\"question\"] # 질문\n",
    "\n",
    "    # Retrieval 실행\n",
    "    documents = retriever.invoke(question)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "    # State에 documents, question 전달\n",
    "\n",
    "\n",
    "# Question + Documents 받아서 RAG 실행\n",
    "def generate(state):\n",
    "\n",
    "    print(\"---생성---\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    print(\"**************DOCUMENTS****************\")\n",
    "    print('\\n---\\n'.join([doc.page_content for doc in documents]))\n",
    "    print(\"***************************************\")\n",
    "\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "    # State에 generation 추가 (나머지는 주어진 값)\n",
    "\n",
    "\n",
    "# Documents 연관성 평가\n",
    "def grade_documents(state):\n",
    "\n",
    "    print(\"---쿼리 연관성 검색---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # 분류 결과가 Relevant인 문서만 저장하기\n",
    "    filtered_docs = []\n",
    "\n",
    "    # True에서 바뀌지 않으면 웹 서치 실행하는 단계로 이동\n",
    "    needed_web_search = True\n",
    "\n",
    "\n",
    "    for doc in documents:\n",
    "\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": doc.page_content}\n",
    "        )['score']\n",
    "\n",
    "\n",
    "        if score=='No':\n",
    "            print(\"---GRADE: 관련성 없음---\")\n",
    "\n",
    "        else:\n",
    "            print(\"---GRADE: 관련성 확인---\")\n",
    "            filtered_docs.append(doc)\n",
    "            needed_web_search =  False\n",
    "\n",
    "\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"needed_web_search\": needed_web_search}\n",
    "    # 관련있는 문서만 추출하여 documents에 업데이트하고, 웹 서치가 필요한지 전달\n",
    "\n",
    "\n",
    "# 질문 Rewriting 체인 실행\n",
    "def transform_query(state):\n",
    "\n",
    "    print(\"---쿼리 재조합---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Re-write\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "\n",
    "    print('BEFORE:', question)\n",
    "    print('AFTER:', better_question)\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "\n",
    "# Tavily로 웹 서치 실행\n",
    "def web_search(state):\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 빈 문서에서 시작하는 이유?\n",
    "    documents = []\n",
    "\n",
    "    get_query_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"주어진 [질문]에 대한 정보를 얻기 위해, 웹 검색을 하고 싶습니다. [질문]을 적절한 영문 쿼리로 변환하세요.\n",
    "쿼리는 주로 단어들의 집합으로 나타내집니다.\"\"\"),\n",
    "        ('user','[질문]: {question}')\n",
    "\n",
    "    ])\n",
    "\n",
    "    # 쿼리 생성 체인\n",
    "    query_chain = get_query_prompt | llm | StrOutputParser()\n",
    "\n",
    "    # 새로운 쿼리 생성\n",
    "    new_query = query_chain.invoke({\"question\": question})\n",
    "\n",
    "\n",
    "    # 새 쿼리로 Web search\n",
    "    docs = tavily.invoke(new_query)\n",
    "\n",
    "    try:\n",
    "        web_results = \"\\n--------\\n\".join([doc[\"content\"] for doc in docs])\n",
    "\n",
    "    except Exception as e: # 400 Error (한국어 검색어인 경우 가끔 나타남)\n",
    "        print(new_query,e)\n",
    "        web_results=''\n",
    "\n",
    "    web_results = Document(page_content=web_results)\n",
    "\n",
    "\n",
    "    print(f\"\"\"---Query Generation---\n",
    "Before: {question}\n",
    "After: {new_query}\n",
    "\"\"\")\n",
    "\n",
    "    print(web_results)\n",
    "\n",
    "    # 검색결과 저장\n",
    "    documents.append(web_results)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCt29f5HYgs-"
   },
   "source": [
    "위 함수들은 그래프의 노드(동그라미) 역할을 했다면,    \n",
    "엣지(마름모) 역할을 하는 함수는 조건 분기의 역할을 수행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "hTTVLOq4YgBh"
   },
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "\n",
    "    print(\"---평가 결과를 확인합니다---\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    needed_web_search = state[\"needed_web_search\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if needed_web_search :# 웹 검색이 필요하면 transform_query 상태로 이동\n",
    "        print(\n",
    "            \"---DECISION: 지금 Context로 답변 불가---\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "\n",
    "\n",
    "    else: # 필요하지 않으면 generate로 이동\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PY8_-fuGZYy7"
   },
   "source": [
    "모든 구성 요소를 그래프로 연결합니다.    \n",
    "노드의 이름과 함수를 결합해 노드를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "ylRSKHfnngVD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1485ae6b0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "\n",
    "workflow = StateGraph(CRAGState)\n",
    "\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"transform_query\", transform_query)\n",
    "workflow.add_node(\"web_search_node\", web_search)\n",
    "\n",
    "# 시작점 : Retrieve\n",
    "workflow.set_entry_point(\"retrieve\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTsQVLYtZzH3"
   },
   "source": [
    "노드들을 연결하는 엣지를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "RnsWgF7XZ20d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1485ae6b0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검색 후 결과 평가\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "# 결과 평가의 결과에 따라 둘 중 하나로 이동하는 분기 엣지\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# 쿼리 재생성 후 웹 서치\n",
    "workflow.add_edge(\"transform_query\", \"web_search_node\")\n",
    "\n",
    "# 웹 서치 후 생성\n",
    "workflow.add_edge(\"web_search_node\", \"generate\")\n",
    "\n",
    "# 생성하고 나면 에이전트 종료\n",
    "workflow.add_edge(\"generate\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JlTGzxGaExQ"
   },
   "source": [
    "구성된 그래프를 컴파일하여 최종적인 Agentic Workflow를 완성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "vsis9SScaD6g"
   },
   "outputs": [],
   "source": [
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "orJ2fyDUPr9B"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x1485ad330>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "9s5SNOnNp8MY"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0hRTw-iaNEB"
   },
   "source": [
    "## LangGraph Agent 실행하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oi6lCM-fbSZH"
   },
   "source": [
    "question을 전달하여 에이전트를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "f-cy-txSngVD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---검색---\n",
      "\"Node 'retrieve':\"\n",
      "'---'\n",
      "---쿼리 연관성 검색---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 없음---\n",
      "---GRADE: 관련성 없음---\n",
      "---GRADE: 관련성 확인---\n",
      "---평가 결과를 확인합니다---\n",
      "---DECISION: GENERATE---\n",
      "\"Node 'grade_documents':\"\n",
      "'---'\n",
      "---생성---\n",
      "**************DOCUMENTS****************\n",
      "described in section 3.2.\n",
      "Self-attention, sometimes called intra-attention is an attention mechanism relating different positions\n",
      "of a single sequence in order to compute a representation of the sequence. Self-attention has been\n",
      "used successfully in a variety of tasks including reading comprehension, abstractive summarization,\n",
      "textual entailment and learning task-independent sentence representations [4, 27, 28, 22].\n",
      "End-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\n",
      "aligned recurrence and have been shown to perform well on simple-language question answering and\n",
      "language modeling tasks [34].\n",
      "To the best of our knowledge, however, the Transformer is the first transduction model relying\n",
      "entirely on self-attention to compute representations of its input and output without using sequence-\n",
      "aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\n",
      "---\n",
      "around each of the sub-layers, followed by layer normalization. We also modify the self-attention\n",
      "sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\n",
      "masking, combined with fact that the output embeddings are offset by one position, ensures that the\n",
      "predictions for position i can depend only on the known outputs at positions less than i.\n",
      "3.2 Attention\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "3\n",
      "---\n",
      "Scaled Dot-Product Attention\n",
      " Multi-Head Attention\n",
      "Figure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\n",
      "attention layers running in parallel.\n",
      "of the values, where the weight assigned to each value is computed by a compatibility function of the\n",
      "query with the corresponding key.\n",
      "3.2.1 Scaled Dot-Product Attention\n",
      "---\n",
      "i ∈ Rdmodel×dk , WK\n",
      "i ∈ Rdmodel×dk , WV\n",
      "i ∈ Rdmodel×dv\n",
      "and WO ∈ Rhdv×dmodel .\n",
      "In this work we employ h = 8 parallel attention layers, or heads. For each of these we use\n",
      "dk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\n",
      "is similar to that of single-head attention with full dimensionality.\n",
      "3.2.3 Applications of Attention in our Model\n",
      "The Transformer uses multi-head attention in three different ways:\n",
      "• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\n",
      "and the memory keys and values come from the output of the encoder. This allows every\n",
      "position in the decoder to attend over all positions in the input sequence. This mimics the\n",
      "typical encoder-decoder attention mechanisms in sequence-to-sequence models such as\n",
      "[38, 2, 9].\n",
      "• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\n",
      "***************************************\n",
      "\"Node 'generate':\"\n",
      "'---'\n",
      "Attention은 쿼리와 키-값 쌍을 매핑하여 출력을 생성하는 함수로, 쿼리와 해당 키 간의 호환성 함수에 따라 각 값에 가중치를 부여하여 출력의 가중합을 계산합니다. Self-attention은 이러한 Attention 메커니즘의 일종으로, 단일 시퀀스 내의 서로 다른 위치 간의 관계를 고려하여 시퀀스의 표현을 계산합니다. Self-attention은 독립적인 문장 표현 학습, 독해, 요약 등 다양한 작업에서 성공적으로 사용되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "inputs = {\"question\": \"Attention과 Self-Attetion은 무엇인가요?\"}\n",
    "\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Node '{key}':\")\n",
    "    pprint(\"---\")\n",
    "\n",
    "print(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "yzibT4BMngVD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---검색---\n",
      "\"Node 'retrieve':\"\n",
      "'---'\n",
      "---쿼리 연관성 검색---\n",
      "---GRADE: 관련성 없음---\n",
      "---GRADE: 관련성 없음---\n",
      "---GRADE: 관련성 없음---\n",
      "---GRADE: 관련성 없음---\n",
      "---GRADE: 관련성 없음---\n",
      "---평가 결과를 확인합니다---\n",
      "---DECISION: 지금 Context로 답변 불가---\n",
      "\"Node 'grade_documents':\"\n",
      "'---'\n",
      "---쿼리 재조합---\n",
      "BEFORE: Who is Sam Altman?\n",
      "AFTER: Sam Altman은 누구인가요?\n",
      "\"Node 'transform_query':\"\n",
      "'---'\n",
      "---WEB SEARCH---\n",
      "---Query Generation---\n",
      "Before: Sam Altman은 누구인가요?\n",
      "After: Query: \"Who is Sam Altman?\"\n",
      "\n",
      "page_content='Sam Altman, the CEO of OpenAI. Before leading OpenAI, Sam Altman was the president of Y Combinator, a startup accelerator that has launched companies including Airbnb, Instacart, and Dropbox. Now Altman is leading one of the hottest and most important companies of the moment: OpenAI, which has launched ChatGPT and, most recently, the AI video generator Sora. During OpenAI’s early years, Altman remained Y Combinator’s president and stayed involved from a distance. Altman raised the first billion-dollar investment from Microsoft, which would provide the Azure cloud service for OpenAI’s large AI models to scale. Altman replaced the title of OpenAI’s AI chatbot, “Chat with GPT-3.5,” with the slightly pithier ChatGPT. French President Emmanuel Macron, left, meets with OpenAI CEO Sam Altman.\n",
      "--------\n",
      "Michael Calore: Sam Altman is the CEO and one of the founders of OpenAI, the generative AI company that launched ChatGPT about two years ago, and essentially ushered in a new era of artificial intelligence. Michael Calore: I think it's important to also make the distinction that there were a lot of companies working on artificial intelligence at this time, about eight or nine years ago, and OpenAI saw themselves as the good guys in the group. Now, there are things that the company is doing that I think are very good, like the idea of a productivity tool or a suite of productivity tools that can help people do their jobs better.\n",
      "--------\n",
      "Who is Sam Altman, the man behind the AI revolution? ... Chicago-born Sam Altman joined Stanford University in 2004 to study computer science, but\n",
      "--------\n",
      "Altman’s contributions to the tech industry, his work in AI ethics, and his vision for the future of AI have left an indelible mark on the world. Sam Altman’s journey from a small town to a leading role in AI research and tech entrepreneurship serves as an inspiration to many, highlighting the possibilities for success through innovation, perseverance, and a commitment to ethical technology development. The overarching lesson from Sam Altman’s life and career is the importance of pursuing one’s passions, adapting to new challenges, and using technology and entrepreneurship to make a positive impact on society. In addition to his work in technology and AI, Sam Altman has been involved in biotechnology, longevity research, and universal basic income (UBI).\n",
      "--------\n",
      "Following the acquisition of Loopt, Altman joined Y Combinator (YC), a prestigious startup accelerator known for nurturing early-stage startups. OpenAI’s mission resonated deeply with Altman, who has long been an advocate for the ethical development and deployment of AI technologies. Under Altman’s leadership, OpenAI has made significant strides in advancing AI research. In a dramatic turn of events in 2023, Sam Altman was unexpectedly fired from his position as CEO of OpenAI, causing a stir within the tech community. As the world continues to grapple with the implications of rapid technological advancement, Altman’s leadership and foresight will undoubtedly play a crucial role in shaping a future that benefits all of humanity. LINKEDIN: https://www.linkedin.com/company/business-over-drinks This offer is available to Business over Drinks listeners, so click on the link above and get started.'\n",
      "\"Node 'web_search_node':\"\n",
      "'---'\n",
      "---생성---\n",
      "**************DOCUMENTS****************\n",
      "Sam Altman, the CEO of OpenAI. Before leading OpenAI, Sam Altman was the president of Y Combinator, a startup accelerator that has launched companies including Airbnb, Instacart, and Dropbox. Now Altman is leading one of the hottest and most important companies of the moment: OpenAI, which has launched ChatGPT and, most recently, the AI video generator Sora. During OpenAI’s early years, Altman remained Y Combinator’s president and stayed involved from a distance. Altman raised the first billion-dollar investment from Microsoft, which would provide the Azure cloud service for OpenAI’s large AI models to scale. Altman replaced the title of OpenAI’s AI chatbot, “Chat with GPT-3.5,” with the slightly pithier ChatGPT. French President Emmanuel Macron, left, meets with OpenAI CEO Sam Altman.\n",
      "--------\n",
      "Michael Calore: Sam Altman is the CEO and one of the founders of OpenAI, the generative AI company that launched ChatGPT about two years ago, and essentially ushered in a new era of artificial intelligence. Michael Calore: I think it's important to also make the distinction that there were a lot of companies working on artificial intelligence at this time, about eight or nine years ago, and OpenAI saw themselves as the good guys in the group. Now, there are things that the company is doing that I think are very good, like the idea of a productivity tool or a suite of productivity tools that can help people do their jobs better.\n",
      "--------\n",
      "Who is Sam Altman, the man behind the AI revolution? ... Chicago-born Sam Altman joined Stanford University in 2004 to study computer science, but\n",
      "--------\n",
      "Altman’s contributions to the tech industry, his work in AI ethics, and his vision for the future of AI have left an indelible mark on the world. Sam Altman’s journey from a small town to a leading role in AI research and tech entrepreneurship serves as an inspiration to many, highlighting the possibilities for success through innovation, perseverance, and a commitment to ethical technology development. The overarching lesson from Sam Altman’s life and career is the importance of pursuing one’s passions, adapting to new challenges, and using technology and entrepreneurship to make a positive impact on society. In addition to his work in technology and AI, Sam Altman has been involved in biotechnology, longevity research, and universal basic income (UBI).\n",
      "--------\n",
      "Following the acquisition of Loopt, Altman joined Y Combinator (YC), a prestigious startup accelerator known for nurturing early-stage startups. OpenAI’s mission resonated deeply with Altman, who has long been an advocate for the ethical development and deployment of AI technologies. Under Altman’s leadership, OpenAI has made significant strides in advancing AI research. In a dramatic turn of events in 2023, Sam Altman was unexpectedly fired from his position as CEO of OpenAI, causing a stir within the tech community. As the world continues to grapple with the implications of rapid technological advancement, Altman’s leadership and foresight will undoubtedly play a crucial role in shaping a future that benefits all of humanity. LINKEDIN: https://www.linkedin.com/company/business-over-drinks This offer is available to Business over Drinks listeners, so click on the link above and get started.\n",
      "***************************************\n",
      "\"Node 'generate':\"\n",
      "'---'\n",
      "샘 알트만(Sam Altman)은 OpenAI의 CEO이자 공동 창립자로, 인공지능 혁명을 이끌고 있는 인물입니다. 그는 Y Combinator의 사장으로서 여러 스타트업을 지원하며 경력을 쌓았고, OpenAI의 윤리적 AI 개발에 깊은 관심을 가지고 있습니다. 알트만은 ChatGPT와 같은 혁신적인 AI 제품을 출시하며 AI 연구를 발전시키는 데 기여했습니다. 2023년에는 OpenAI의 CEO로서 갑작스럽게 해임되는 사건이 발생했지만, 그의 리더십과 비전은 여전히 기술 산업에 큰 영향을 미치고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"Who is Sam Altman?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Node '{key}':\")\n",
    "    pprint(\"---\")\n",
    "\n",
    "print(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "-ed_X1rsngVD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---검색---\n",
      "\"Node 'retrieve':\"\n",
      "'---'\n",
      "---쿼리 연관성 검색---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 없음---\n",
      "---평가 결과를 확인합니다---\n",
      "---DECISION: GENERATE---\n",
      "\"Node 'grade_documents':\"\n",
      "'---'\n",
      "---생성---\n",
      "**************DOCUMENTS****************\n",
      "respectively.\n",
      "3.1 Encoder and Decoder Stacks\n",
      "Encoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\n",
      "sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\n",
      "wise fully connected feed-forward network. We employ a residual connection [11] around each of\n",
      "the two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\n",
      "LayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\n",
      "itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\n",
      "layers, produce outputs of dimension dmodel = 512.\n",
      "Decoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\n",
      "sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\n",
      "attention over the output of the encoder stack. Similar to the encoder, we employ residual connections\n",
      "---\n",
      "• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\n",
      "and queries come from the same place, in this case, the output of the previous layer in the\n",
      "encoder. Each position in the encoder can attend to all positions in the previous layer of the\n",
      "encoder.\n",
      "• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\n",
      "all positions in the decoder up to and including that position. We need to prevent leftward\n",
      "information flow in the decoder to preserve the auto-regressive property. We implement this\n",
      "inside of scaled dot-product attention by masking out (setting to −∞) all values in the input\n",
      "of the softmax which correspond to illegal connections. See Figure 2.\n",
      "3.3 Position-wise Feed-Forward Networks\n",
      "In addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\n",
      "connected feed-forward network, which is applied to each position separately and identically. This\n",
      "---\n",
      "connected feed-forward network, which is applied to each position separately and identically. This\n",
      "consists of two linear transformations with a ReLU activation in between.\n",
      "FFN(x) = max(0, xW1 + b1)W2 + b2 (2)\n",
      "While the linear transformations are the same across different positions, they use different parameters\n",
      "from layer to layer. Another way of describing this is as two convolutions with kernel size 1.\n",
      "The dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\n",
      "dff = 2048.\n",
      "3.4 Embeddings and Softmax\n",
      "Similarly to other sequence transduction models, we use learned embeddings to convert the input\n",
      "tokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\n",
      "mation and softmax function to convert the decoder output to predicted next-token probabilities. In\n",
      "our model, we share the same weight matrix between the two embedding layers and the pre-softmax\n",
      "---\n",
      "aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\n",
      "self-attention and discuss its advantages over models such as [17, 18] and [9].\n",
      "3 Model Architecture\n",
      "Most competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35].\n",
      "Here, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\n",
      "of continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\n",
      "sequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\n",
      "[10], consuming the previously generated symbols as additional input when generating the next.\n",
      "2\n",
      "---\n",
      "Figure 1: The Transformer - model architecture.\n",
      "The Transformer follows this overall architecture using stacked self-attention and point-wise, fully\n",
      "connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\n",
      "respectively.\n",
      "3.1 Encoder and Decoder Stacks\n",
      "***************************************\n",
      "\"Node 'generate':\"\n",
      "'---'\n",
      "디코더(Decoder)는 입력 시퀀스를 기반으로 출력 시퀀스를 생성하는 신경망의 구성 요소입니다. 디코더는 N=6개의 동일한 층으로 구성되어 있으며, 각 층은 두 개의 서브 레이어와 추가로 인코더 스택의 출력을 대상으로 하는 다중 헤드 주의(attention) 서브 레이어를 포함합니다. 디코더는 이전에 생성된 심볼을 추가 입력으로 사용하여 다음 심볼을 생성하는 오토 회귀(auto-regressive) 특성을 가지고 있습니다. 이러한 구조를 통해 디코더는 시퀀스 생성 작업을 효과적으로 수행할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"Decorder가 뭐야?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "\n",
    "        pprint(f\"Node '{key}':\")\n",
    "    pprint(\"---\")\n",
    "\n",
    "\n",
    "print(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "pQdVS1SHp8MY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---검색---\n",
      "\"Node 'retrieve':\"\n",
      "'\\n---\\n'\n",
      "---쿼리 연관성 검색---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 확인---\n",
      "---평가 결과를 확인합니다---\n",
      "---DECISION: GENERATE---\n",
      "\"Node 'grade_documents':\"\n",
      "'\\n---\\n'\n",
      "---생성---\n",
      "**************DOCUMENTS****************\n",
      "aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\n",
      "self-attention and discuss its advantages over models such as [17, 18] and [9].\n",
      "3 Model Architecture\n",
      "Most competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35].\n",
      "Here, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\n",
      "of continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\n",
      "sequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\n",
      "[10], consuming the previously generated symbols as additional input when generating the next.\n",
      "2\n",
      "---\n",
      "Figure 1: The Transformer - model architecture.\n",
      "The Transformer follows this overall architecture using stacked self-attention and point-wise, fully\n",
      "connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\n",
      "respectively.\n",
      "3.1 Encoder and Decoder Stacks\n",
      "---\n",
      "sequence lengths, as memory constraints limit batching across examples. Recent work has achieved\n",
      "significant improvements in computational efficiency through factorization tricks [21] and conditional\n",
      "computation [32], while also improving model performance in case of the latter. The fundamental\n",
      "constraint of sequential computation, however, remains.\n",
      "Attention mechanisms have become an integral part of compelling sequence modeling and transduc-\n",
      "tion models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
      "the input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\n",
      "are used in conjunction with a recurrent network.\n",
      "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
      "relying entirely on an attention mechanism to draw global dependencies between input and output.\n",
      "The Transformer allows for significantly more parallelization and can reach a new state of the art in\n",
      "---\n",
      "Parser [29] even when training only on the WSJ training set of 40K sentences.\n",
      "7 Conclusion\n",
      "In this work, we presented the Transformer, the first sequence transduction model based entirely on\n",
      "attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\n",
      "multi-headed self-attention.\n",
      "For translation tasks, the Transformer can be trained significantly faster than architectures based\n",
      "on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\n",
      "English-to-French translation tasks, we achieve a new state of the art. In the former task our best\n",
      "model outperforms even all previously reported ensembles.\n",
      "We are excited about the future of attention-based models and plan to apply them to other tasks. We\n",
      "plan to extend the Transformer to problems involving input and output modalities other than text and\n",
      "to investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\n",
      "---\n",
      "described in section 3.2.\n",
      "Self-attention, sometimes called intra-attention is an attention mechanism relating different positions\n",
      "of a single sequence in order to compute a representation of the sequence. Self-attention has been\n",
      "used successfully in a variety of tasks including reading comprehension, abstractive summarization,\n",
      "textual entailment and learning task-independent sentence representations [4, 27, 28, 22].\n",
      "End-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\n",
      "aligned recurrence and have been shown to perform well on simple-language question answering and\n",
      "language modeling tasks [34].\n",
      "To the best of our knowledge, however, the Transformer is the first transduction model relying\n",
      "entirely on self-attention to compute representations of its input and output without using sequence-\n",
      "aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\n",
      "---\n",
      "connected feed-forward network, which is applied to each position separately and identically. This\n",
      "consists of two linear transformations with a ReLU activation in between.\n",
      "FFN(x) = max(0, xW1 + b1)W2 + b2 (2)\n",
      "While the linear transformations are the same across different positions, they use different parameters\n",
      "from layer to layer. Another way of describing this is as two convolutions with kernel size 1.\n",
      "The dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\n",
      "dff = 2048.\n",
      "3.4 Embeddings and Softmax\n",
      "Similarly to other sequence transduction models, we use learned embeddings to convert the input\n",
      "tokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\n",
      "mation and softmax function to convert the decoder output to predicted next-token probabilities. In\n",
      "our model, we share the same weight matrix between the two embedding layers and the pre-softmax\n",
      "***************************************\n",
      "\"Node 'generate':\"\n",
      "'\\n---\\n'\n",
      "Transformer 모델의 주요 특징은 순환 신경망(RNN)이나 합성곱 신경망(CNN)을 사용하지 않고, 전적으로 자기 주의(attention) 메커니즘에 의존하여 입력과 출력 간의 전역 의존성을 모델링한다는 점입니다. 이 구조는 인코더-디코더 아키텍처를 따르며, 인코더는 입력 시퀀스를 연속 표현으로 변환하고, 디코더는 이 표현을 바탕으로 출력 시퀀스를 생성합니다. 또한, Transformer는 병렬 처리를 크게 향상시켜 훈련 속도를 높이며, 번역 작업에서 기존의 모델들보다 우수한 성능을 보여줍니다.\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"Transformer 모델의 특징이 뭐야?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "\n",
    "        pprint(f\"Node '{key}':\")\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "print(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfZR7UJH_2iW"
   },
   "source": [
    "# 실습) Corrective RAG Scheme 수정하기   \n",
    "\n",
    "검색 결과 중 irrelevant한 정보가 존재하면, 웹 검색을 통해 이를 보충하도록 flow를 수정해 보세요.   \n",
    "**Hint**: 웹 검색을 수행하는 조건을 변경하고, 웹 검색을 할 때 기존 문서값을 가져오도록 만들어 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzWGocdQ_2iW"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
